% !TeX spellcheck = en_GB
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                        %
%     Master thesis LaTeX template       %
%  compliant with the SZJK regulations   %
%                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                        %
%  (c) Krzysztof Simiński, 2018-2023     %
%                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                        %
% The latest version of the templates is %
% available at                           %
% github.com/ksiminski/polsl-aei-theses  %
%                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%
% This LaTeX project formats the final thesis
% with compliance to the SZJK regulations.
% Please to not change formatting (fonts, margins,
% bolds, italics, etc).
%
% You can compile the project in several ways.
%
% 1. pdfLaTeX compilation
%
% pdflatex main
% bibtex   main
% pdflatex main
% pdflatex main
%
%
% 2. XeLaTeX compilation
%
% Compilation with the XeLaTeX engine inserts Calibri font
% in the title page. Of course the font has to be installed.
%

% xelatex main
% bibtex  main
% xelatex main
% xelatex main
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% If you have any questions, remarks, just send me an email: %
%            krzysztof.siminski(at)polsl.pl               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% We would like to improve the LaTeX templates
% of final theses. By answering the questions
% in the survey whose address your can find below
% you help us to do so. The survey is completely
% anonimous. Thank you!
%
% https://docs.google.com/forms/d/e/1FAIpQLScyllVxNKzKFHfILDfdbwC-jvT8YL0RSTFs-s27UGw9CKn-fQ/viewform?usp=sf_link
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
% CUSTOMISATION OF THE THESIS                 %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Please customise your thesis with the macros below.

% TODO
%% author:
\newcommand{\FirstNameAuthor}{Klaudia}
\newcommand{\SurnameAuthor}{Janecka}
\newcommand{\IdAuthor}{$\langle$student id$\rangle$}  % (remove $\langle$ and $\rangle)

% coauthor:
%\newcommand{\FirstNameCoauthor}{First Names}  % If there is a coauthor, put the first names here.
%\newcommand{\SurnameCoauthor}{Surname}        % If there is a coauthor, put the surnames here.
%\newcommand{\IdCoauthor}{$\langle$student id$\rangle$} % If there is a coauthor, put the student id here (remove $\langle$ and $\rangle)
% If there is no coathor, leave the definitions empty like below. If a coauthor exists, comment the lines below.
\newcommand{\FirstNameCoauthor}{} % If there is only one author, leave the definitions empty.
\newcommand{\SurnameCoauthor}{}   % If there is only one author, leave the definitions empty.
\newcommand{\IdCoauthor}{}        % If there is only one author, leave the definitions empty.
%%%%%%%%%%

\newcommand{\Supervisor}{$\langle$title first name surname$\rangle$}  % supervisor (remove $\langle$ and $\rangle)
\newcommand{\Title}{Design and implementation of a microservice-oriented web application that collects data from external services.}
\newcommand{\TitleAlt}{Thesis title in Polish}
\newcommand{\Program}{Informatyka}
\newcommand{\Specialisation}{Informatics}
\newcommand{\Id}{$\langle$your student id$\rangle$}                   % remove \langle and \rangle in final version
\newcommand{\Departament}{$\langle$departament name$\rangle$}         % remove \langle and \rangle in final version
\newcommand{\Surname}{Janecka}
\newcommand{\Firstnames}{Klaudia}

% If you have a consultant for your thesis, put their name below ...
%\newcommand{\Consultant}{$\langle$title first name surname$\rangle$}  %  (remove $\langle$ and $\rangle)
% ... else leave the braces empty:
\newcommand{\Consultant}{} % no consultant

% end of thesis customisation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
% END OF CUSTOMISATION                        %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
%   PLEASE DO NOT MODIFY THE SETTINGS BELOW!  %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[12pt]{report}
\usepackage[utf8]{inputenc}                                      
\usepackage[T1]{fontenc}  
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage[polish,british]{babel} 
\usepackage{indentfirst}
\usepackage{xurl}
\usepackage{xstring}
\usepackage{ifthen}
\usepackage{enumitem}
\usepackage{tabularx} 
\usepackage{nameref}
\usepackage{ifxetex}
\usepackage{multirow}
\ifxetex
	\usepackage{fontspec}
	\defaultfontfeatures{Mapping=tex—text} % to support TeX conventions like ``——-''
	\usepackage{xunicode} % Unicode support for LaTeX character names (accents, European chars, etc)
	\usepackage{xltxtra} % Extra customizations for XeLaTeX
\else
	\usepackage{lmodern}
\fi



\usepackage[margin=2.5cm]{geometry}
\usepackage{graphicx} 
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{mathtools}
\usepackage{geometry}
\usepackage{subcaption}   % subfigures
\usepackage[page]{appendix} % toc,
\usepackage{caption}
\usepackage{adjustbox}
\setcounter{tocdepth}{5}
\setcounter{secnumdepth}{5}
\setcounter{secnumdepth}{6}
\usepackage{titlesec}
% Define subsubsubsection command

\usepackage{csquotes}

\usepackage[backend=biber]{biblatex}
\addbibresource{mybibliography.bib} 

\usepackage{ifmtarg}   % empty commands  

\usepackage{setspace}
\onehalfspacing


\frenchspacing



%%%% TODO LIST GENERATOR %%%%%%%%%

\usepackage{color}
\definecolor{brickred}      {cmyk}{0   , 0.89, 0.94, 0.28}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\makeatletter \newcommand \kslistofremarks{\section*{Remarks} \@starttoc{rks}}
  \newcommand\l@uwagas[2]
    {\par\noindent \textbf{#2:} %\parbox{10cm}
{#1}\par} \makeatother


\newcommand{\ksremark}[1]{%
{%\marginpar{\textdbend}
{\color{brickred}{[#1]}}}%
\addcontentsline{rks}{uwagas}{\protect{#1}}%
}










%%%%%%%%%%%%%% END OF TODO LIST GENERATOR %%%%%%%%%%%  

\newcommand{\printCoauthor}{%		
    \StrLen{\FirstNameCoauthor}[\FNCoALen]
    \ifthenelse{\FNCoALen > 0}%
    {%
		{\large\bfseries\Coauthor\par}
	
		{\normalsize\bfseries \LeftId: \IdCoauthor\par}
    }%
    {}
} 

%%%%%%%%%%%%%%%%%%%%%
\newcommand{\autor}{%		
    \StrLen{\FirstNameCoauthor}[\FNCoALenXX]
    \ifthenelse{\FNCoALenXX > 0}%
    {\FirstNameAuthor\ \SurnameAuthor, \FirstNameCoauthor\ \SurnameCoauthor}%
	{\FirstNameAuthor\ \SurnameAuthor}%
}
%%%%%%%%%%%%%%%%%%%%%

\StrLen{\FirstNameCoauthor}[\FNCoALen]
\ifthenelse{\FNCoALen > 0}%
{%
\author{\FirstNameAuthor\ \SurnameAuthor, \FirstNameCoauthor\ \SurnameCoauthor}
}%
{%
\author{\FirstNameAuthor\ \SurnameAuthor}
}%

%%%%%%%%%%%% FANCY HEADERS %%%%%%%%%%%%%%%
% no capitalisation of headers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LO]{\nouppercase{\it\rightmark}}
\fancyhead[RE]{\nouppercase{\it\leftmark}}
\fancyhead[LE,RO]{\it\thepage}

\setlength{\headheight}{14.49998pt}
\addtolength{\topmargin}{-2.49998pt}

\fancypagestyle{onlyPageNumbers}{%
   \fancyhf{} 
   \fancyhead[LE,RO]{\it\thepage}
}

\fancypagestyle{noNumbers}{%
   \fancyhf{} 
   \fancyhead[LE,RO]{}
}


\fancypagestyle{PageNumbersChapterTitles}{%
   \fancyhf{} 
   \fancyhead[LO]{\nouppercase{\Firstnames\ \Surname}}
   \fancyhead[RE]{\nouppercase{\leftmark}} 
   \fancyfoot[CE, CO]{\thepage}
}
 


%%%%%%%%%%%%%%%%%%%%%%%%%%%








\newcounter{pagesWithoutNumbers}

%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\newcommand{\printOpiekun}[1]{%		

    \StrLen{\Consultant}[\mystringlen]
    \ifthenelse{\mystringlen > 0}%
    {%
       {\large{\bfseries CONSULTANT}\par}
       
       {\large{\bfseries \Consultant}\par}
    }%
    {}
} 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
% Please do not modify the lines below!
\newcommand{\Author}{\FirstNameAuthor\ \MakeUppercase{\SurnameAuthor}} 
\newcommand{\Coauthor}{\FirstNameCoauthor\ \MakeUppercase{\SurnameCoauthor}}
\newcommand{\Type}{MASTER THESIS}
\newcommand{\Faculty}{Faculty of Automatic Control, Electronics and Computer Science}
\newcommand{\Polsl}{Silesian University of Technology}
\newcommand{\Logo}{politechnika_sl_logo_bw_pion_en.pdf}
\newcommand{\LeftId}{Student identification number}
\newcommand{\LeftProgram}{Programme}
\newcommand{\LeftSpecialisation}{Specialisation}
\newcommand{\LeftSUPERVISOR}{SUPERVISOR}
\newcommand{\LeftDEPARTMENT}{DEPARTMENT}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
% END OF SETTINGS                             %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
% MY PACKAGES, SETTINGS ETC.                  %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Put your packages, macros, setting here.


 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% listings
% packages: listings or minted
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

% package listings
\usepackage{listings}
\lstset{%
morekeywords={var,get,set},% add the keyword you need
language=[Sharp]C% C, Matlab, Python, SQL, TeX, XML, bash, ... – vide https://www.ctan.org/pkg/listings
commentstyle=\textit,%
identifierstyle=\textsf,%
keywordstyle=\sffamily\bfseries, %\texttt, %
%captionpos=b,%
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
tabsize=3,%
frame=lines,%
numbers=left,%
numberstyle=\tiny,%
numbersep=5pt,%
breaklines=true,%
breakpages=false,%
escapeinside={@*}{*@},%
}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% package minted
% \usepackage{minted}

% This package requires a special command line option in compilation
% pdflatex -shell-escape main.tex
% xelatex  -shell-escape main.tex

%\usepackage[chapter]{minted} % [section]
%%\usemintedstyle{bw}   % black and white codes
%
%\setminted % https://ctan.org/pkg/minted
%{
%%fontsize=\normalsize,%\footnotesize,
%%captionpos=b,%
%tabsize=3,%
%frame=lines,%
%framesep=2mm,
%numbers=left,%
%numbersep=5pt,%
%breaklines=true,%
%escapeinside=@@,%
%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
% END OF MY PACKAGES, SETTINGS ETC.           %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
%\kslistofremarks

\frontmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                             %
%    PLEASE DO NOT MODIFY THE TITLE PAGE!     %
%                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%  TITLE PAGE %%%%%%%%%%%%%%%%%%%
\pagestyle{empty}
{
	\newgeometry{top=1.5cm,%
	             bottom=2.5cm,%
	             left=3cm,
	             right=2.5cm}
 
	\ifxetex 
	  \begingroup
	  \setsansfont{Calibri}
	   
	\fi 
	 \sffamily
	\begin{center}
	\includegraphics[width=50mm]{\Logo}
	 
	
	{\Large\bfseries\Type\par}
	
	\vfill  \vfill  
			 
	{\large\Title\par}
	
	\vfill  
		
	{\large\bfseries\Author\par}
	
	{\normalsize\bfseries \LeftId: \IdAuthor}

	\printCoauthor
	
	\vfill  		
 
	{\large{\bfseries \LeftProgram:} \Program\par} 
	
	{\large{\bfseries \LeftSpecialisation:} \Specialisation\par} 
	 		
	\vfill  \vfill 	\vfill 	\vfill 	\vfill 	\vfill 	\vfill  
	 
	{\large{\bfseries \LeftSUPERVISOR}\par}
	
	{\large{\bfseries \Supervisor}\par}
				
	{\large{\bfseries \LeftDEPARTMENT\ \Departament} \par}
		
	{\large{\bfseries \Faculty}\par}
		
	\vfill  \vfill  

    	
    \printOpiekun{\Consultant}
    
	\vfill  \vfill  
		
    {\large\bfseries  Gliwice \the\year}

   \end{center}	
       \ifxetex 
       	  \endgroup
       \fi
	\restoregeometry
}
  


\cleardoublepage

\rmfamily\normalfont
\pagestyle{empty}


%%% Let's start the thesis %%%%

% TODO
\subsubsection*{Thesis title}  
\Title

\subsubsection*{Abstract} 
(Thesis abstract – to be copied into an appropriate field during an electronic submission – in English.)
The investigations covered in this papers are related to the Microservices architecture. The main aim is to investigate the communication aspects within microservices architecture and their impact on the system performance, scalability and it's overall efficiency.
The knowledge about the inter-services communication is crucial to build robust distributed systems. 
The study delves into various communication patterns and technologies commonly used in the microservices architecture, providing insights about its limitations, advantages and impact on the whole system behaviour. 
 
\subsubsection*{Key words}  


\subsubsection*{Tytuł pracy}
\begin{otherlanguage}{polish}
\TitleAlt
\end{otherlanguage}

\subsubsection*{Streszczenie} 
\begin{otherlanguage}{polish}
(Streszczenie pracy – odpowiednie pole w systemie APD powinno zawierać kopię tego streszczenia.)
\end{otherlanguage}

\subsubsection*{Słowa kluczowe} 
\begin{otherlanguage}{polish}

\end{otherlanguage}




%%%%%%%%%%%%%%%%%% Table of contents %%%%%%%%%%%%%%%%%%%%%%
% Add \thispagestyle{empty} to the toc file (main.toc), because \pagestyle{empty} doesn't work if the TOC has multiple pages
\addtocontents{toc}{\protect\thispagestyle{empty}}
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{pagesWithoutNumbers}{\value{page}}
\mainmatter
\pagestyle{empty}

\cleardoublepage
\pagestyle{PageNumbersChapterTitles}

%%%%%%%%%%%%%% body of the thesis %%%%%%%%%%%%%%%%%

% TODO
\chapter{Introduction}
The following chapter will cover the introduction to the problem domain. It will define the scope of work, present a brief description of the developed system, and outline the conducted research.

\section{Introduction to the problem domain}
Nowadays, IT solutions are commonly the core of maintenance and organization of many products and companies. The system for any enterprise with a notable size is  very complex and composed of a  few independent solutions. The growth of the system commonly relates to the new system functionalities, connection to resources provided by new business partners or new technological solutions, such as cloud services, which have recently been a trend in software development. Due to the connection between them, such as infrastructure is for example the so called ``Spaghetti architecture". [figure 1.1]  illustrates an example of an inefficient and hard to manage IT solution.

 \begin{figure}
\centering
  \includegraphics[width=0.5\textwidth]{spaghetti.jpg}
\caption{Spaghetti architecture diagram}
\label{fig1}
\end{figure}

Referring to this problem, many architectural patterns have been created over the years. Microservices are an example of an approach of software architecture which addresses many modern application challenges ~\cite{microserviceschallanges:1} . Microservices offer several advantages including scalability and flexibility in managing complex applications. The most important point of designing microservices architecture is a good selection of technology and a method of communication between individual subsystems. The choice of the pattern is sophisticated, because it requires cross-sectional knowledge of a wide range of technologies available on the market. The technology should meet the requirements of the individual system and simultaneously is supposed to  be optimal     in relation to the costs.

\section{Contribution and objective of the thesis}
The main purpose of the thesis is to provide the solution to the choice of a proper type of communication in the process of creating a  (complex distributed system in microservices architecture.
The goals of the thesis are as follows:
\begin{itemize}
\item To study and analyze existing communication technologies, 
\item To identify the challenges of collaboration between microservices,
\item To experimentally verify selected types of communication and various data packages,
\item To identify the configuration properties required to establish  the best performance communication between microservices by means of using selected technology,
\item To study the best choose of technology depending on the demand of the system, => TODO
\item To examine the cost and difficulties in implementing selected technology pattern.
\end{itemize}
For the purpose of conducting a  research for the  master’s thesis, a system based on the microservices architecture was developed, along with the creation of datasets.
The system is composed of multiple applications. It creates the space to perform experiments with multiple communication patterns. There is one publisher application which sends the data to multiple separate client’s applications. Each application stands for the representation of each communication pattern.
Datasets were designed in various forms to perform experiments for a few different purposes of communication between subsystems. Over the study, metrics have been collected at multiple stages [tutaj moze wiecej dopisze jak skoncze badania].
The study ends with a simulation emulating the real-word scenario of data transmission. The data is sent to the robotics simulator  that simulates  environment simultaneously  impacting the data transmission to the robot. This action triggers the robot’s motion. It becomes possible to gain the insights about how the type of communication influences  the trajectory and  at the same time evaluate the  efficiency  of the robot’s motion. The findings of this study have the potential to contribute to the development of more efficient and optimized communication strategies within microservices-based applications.

\section{Overview of the literature}
In this section, a detailed state of the art review is presented, and this analysis was restricted to the papers published between 2015 and 2023. The  information about the communication types and data serialization techniques was  collected from various sources such as official documents, scientific theses, blogs and video conferences. The collaboration between microservices is currently under the constant development and research. New technology solutions, such as cloud architecutres enables to increase the performance and efficiency of the communication.  Most of literatures provide a brief comparison between  the two selected  technologies. However  these  kinds  of research were also very helpful. They allow analyzing a specific use case of the  chosen patterns. 
The  following articles which were found  during the investigation, and they are the closest to the topic of  master’s thesis.

In \cite{performanceEvaluation:2} Fernandes et al. provided the survey of performance in REST API in competition to Advanced Message Queuing Protocol in mobile development environment. In the article, the authors present a description of these technologies, with a focus on the introduction of asynchronous communication as a promising solution to data transfer using massive quantities of data. For performance studies RabbitMQ supporting the AMPQ Protocol is taken into consideration. To provide a result, the authors conduct multiple experiments in created Java back-end system using large amounts of data. In the first experiment, the authors focused on examining the interaction between a user application and RabbitMQ, a message broker, using the AMQP protocol. Throughout a thirty minute experiment, the user application continuously sent messages to RabbitMQ. However, a notable aspect of this experiment was the absence of any active consumer (back-end service) connected to RabbitMQ during the message transmission. This design allowed the authors to observe RabbitMQ's behavior when handling incoming messages without immediate recipients. Moving on to the second experiment, the user application's objective was to send messages to a Web service server for a continuous period of 30 minutes, utilizing the HTTP protocol for communication. Subsequently, the Web service, upon receiving these messages, established communication with a database using the Java Database Connectivity driver to store the incoming messages. Through this setup, the authors sought to evaluate the end-to-end message flow, analyzing the efficiency and reliability of the communication and data storage process between the user application, Web service, and the database. In the third experiment, the user application once again sent messages to RabbitMQ using the AMQP protocol, as described in the first experiment. However, this time, the authors introduced an active consumer (back-end service) connected RabbitMQ. The consumer's role involved reading the incoming messages from RabbitMQ, processing them, and using the Java Database Connectivity driver driver to connect to the database and store the processed messages. This experimental configuration allowed the authors to assess the overall performance and effectiveness of the message processing pipeline, particularly in a real-time scenario with an active consumer. The authors found out  that the application which is  supposed to exchange an large amount of data should use RabbitMQ. They confirmed that RabbitMq  sent the larger number of messages per second and consumed less mobile device resources

 In \cite{multitenant:3} thesis author analyzes the multitenant system in microservices architecture which is based on the events. A significant key is that one instance called tenant manager serves multiple  tenants . It gains more  economical benefits than by  creating tenant manager instance for each customer’s  application. The use of microservices is significant to solve the problem because it helps in keeping all the  modules independent, consequently allowing tenants to choose  their own technology stack and in continous-delivery to perform some customization quicky   without  affecting other tenant ‘s system. It is a perfect solution  to  a  tenant customization to meet  a single customer’s  needs and a feature requested by one organisation without  affecting  any of the other organization. The system presented in the paper focuses on the tenant-islotation and the reduced numer of application programming interface (API) calls. Microservices are communicating with each other using RabbitMq and Azure Service Bus with isolated topics for each tenant. Author provides complex analyzys of benefits of each event bus, putting focus on the security and the ease of setting up the environment.

After the completion of literature review, it is confirmed that this topic  poses a  very common problem nowadays   and the choice of an appropriate connection type and its configuration when designing web applications becomes quite a big challenge.

\section{Short summary of chapters}

TODO IN THE LATE STATE


\chapter{Overview of terminology and technology evolution}

This chapter covers the brief description of software architectures and patterns strictly related with the problem domain. It includes a comparison of  base architectures in relation to the microservices. This chapter also provides an comprehensive analysis of the evolution of Microservices architecture. It presents its origins, emphasizing the core motivation aspects leading to its creation. In this chapter the history context will be examined. It is worth mentioning that  the industrial software needs  resulted in  the development of the technology that shaped the emergence of microservices architecture as a prominent model in software engineering for complex systems.

\section{Architecture patterns}
\subsection{Monolith architecture}

To analyse the microservices it is worth mentioning the monolith architecture, which is  a traditional model of the software program. Monolith is built  as a single unit, all the code is deployed as an single unit. It is self-contained and independent of other applications. It can be composed of a single module or multiple modules inside a single process. Under one monolith application multiple developers teams could be working,  on different segments of the application. The disadvantage of monolith is the difficulty in making changes. Due to this inconvenience multiple problems with blocking each other by waiting for a change of the same piece of the code could occur. Any change, even a small one, involves updating the entire stack and deploying the updated version, which is very time consuming when the system is large \cite{monolith:4}.
The communication between modules in the monolith architecture is performed using a local method invocation. The intermodule communication could be a problematic solution. This pattern is direct and synchronous, so if the called module is not available within the system , the caller module will be impacted. The system could be blocked for the indefinite time or has to wait till the system returns the time-out errors, leading to report of the system issue. It becomes particularly significant for example when the calling and called methods are responsible for generating and managing data respectively. If the function responsible for data analysis encounters parsing error, also the subsystem responsible for generating data would stop. This underscores the critical importance of establishing a robust error handling mechanism and ensuring that all business logic relies on a system capable of perfect handling errors and appropriately responding to failures.
However monolith has also some advantages:
\begin{itemize}
\item All the code located in one place is easier to debug,
\item One executable file is easier to deploy than multiple files from multiple subsystems, 
\item End-to-end testing can be performed faster than in the distributed systems.
\end{itemize}
\begin{figure}[h]
\centering
  \includegraphics[width=0.8\textwidth]{monolith.png}
\caption{Monolith diagram}
\label{fig1}
\end{figure}
 
\subsection{Service-oriented architecture}
The heavyweight nature of monolith architecture has slowly been decomposed decomposed into modules. This process has led to the formation of a new architecture known as service-oriented architecture (SOA).
Modules communicate using the Enterprise Service Bus. Software-oriented architecture manages and coordinates the services delivered through this layer. For the whole system Enterprise Service Bus is single point of failure and if any damage or delay occur the system the entire system could be affected and overwhelmed. Modules communicate using the Enterprise Service Bus. Software-oriented architecture manages and coordinates the services delivered through this layer. 
Modules perform  various type of operations and transactions. There is no strict division into individual role for a particular module. The whole system uses a single dedicated database engine. The application under consideration is comprised of four different types of services:

\begin{description}
\item \textbf{Functional services}\\
The services which are responsible for the businesses operations for the application. It encapsulates the business logic and provides functionality that can  be accessed by other components within the system.
\item \textbf{Enterprise services}\\
The services which implement the functionality required by the system. It integrates multiple functional services to deliver end-to-end functionality. The service which performs coordination of various business processes across different subsystems or applications, could be given as an example of enterprise service.
\item \textbf{Application services}\\
The services which are responsible for development and deployment. They provide the set of tools such as development frameworks, application deployment platforms, and runtime environments which could be used to perform build, deploy and manage the application within  the environment.
\item \textbf{Infrastructure services}\\
The services which are related to the underlying technical infrastructure of a system.  These services could be responsible for the authentication, security or data management. They could also handle the communication protocols.  	
\end{description}
The service-oriented architecture is a precursor of microservices architecture. How ever these architectures are neither comparable and nor compatible. There are a few significant discrepancies  between them. The Service-oriented architecture differs in the scope. In Service-oriented architecture modules are shared and reused enterprise-wide. For example the scope of the application may include the entire department in the company or  a complex subsystem, which could subsequently consist of full user’s  authorization  and the business logic (e.g. administrator module for user’s management).

\begin{figure}[!]
\centering
  \includegraphics[width=0.6\textwidth]{soa.png}
\caption{Service-oriented architecture diagram}
\label{fig1}
\end{figure}
 
\subsection{Microservices architecture}
Service-oriented architecture was a precursor  to  microservices, laying the foundations  for the development of the  ideas related to the modularization of services and applications. Microservices, although inspired by SOA architecture, have extended the concept of modularity. Microservices not only applications in order to optimize the amount of functions and data, but also segregate operations in terms of business logic basing on the Domain Driven Design \cite{dddmicroservices:4}. Each microservice  has both, a  single responsibility for the system and a  separate database engine. Microservices are discussed in more detail in the next chapers.
 
 \begin{figure}[h]
\centering
  \includegraphics[width=0.6\textwidth]{microservices.png}
\caption{Microservices diagram}
\label{fig1}
\end{figure}
\subsubsection{Domain Driven Design}
Domain driven Design is an approach to the software development which concentrates on modelling software architecture to match a domain, which in context of software development reefers to the business. It leads to create the domain models, software abstractions encapsulating complex business logic, to compeer as much as is possible the business reality and code.  The main goal of Domain Driven Development is to bring the technical and and business aspects of the design process together \cite{Rosiek2021:12}.
DDD introduces the idea of strategic design, where the entire system is divided into bounded contexts, each encapsulating a specific domain and its associated rules. Bounded contexts provide a clear separation between different aspects of the system, enabling independent development and maintenance. 
At the heart of Domain-Driven Design is the concept of creating a ubiquitous language, a common vocabulary that is understood both by the technical team and the business stakeholders. This shared language acts as a bridge, fostering a deep understanding of the domain's intricacies across all parties involved. It ensures that technical discussions are carried out using terms that resonate with business experts, enhancing clarity and minimizing misunderstandings.


\chapter{Microservices architecture}
The term ``Microservice" defines the small application which has a single responsibility to the whole system. It has only one reason for changing or being replaced.
Adrian Cockcroft, a famous technologist and strategist, defines a microservices architecture as a service-oriented architecture consisting of loosely coupled components that operate within well-defined boundaries \cite{Adrian:5}. Loosely coupled means that services can be updated independently, without requiring changes to other services. If you have a collection of small, specialised services that still need to be updated simultaneously, they cannot be considered as microservices. There is a lack of loose coupling principle between them \cite{modelingwithddd:6}

The idea of the microservices is related to the demand of scaling along different axes independently. This is a big trend in modern software architecture so studying  it in the  perspective of communication and data flow is extremely important and even indispensable.

\section{Evolution of software architecture}

The history of microservices can be traced back to the 1990s, when the first ideas and concepts of distributed software architecture emerged. However, the term ’microservices’ has only become popular in the last decade, and their development was linked to advances in technology and changes in approaches to application development \cite{DeGiacomo2021:7}.

An Early work on microservices focused on finding better ways to create service-based software. One important step was the introduction of Service-Oriented Architecture (SOA) as an approach to creating modular and loosely coupled services. Service-Oriented Architecture has made it possible to create applications consisting of independent components that can be easily scaled and developed.
In 2011, the term ``microservices’ was introduced by Martin Fowler and James Lewis in their article \cite{fowler2014microservices:8}.
 
\subsection{Netflix as a microservices pioneer}
Netflix, Inc.  played an important role in developing and promoting microservices architecture. Netflix, Inc. was one of the pioneers in using microservices as the main approach to building its streaming platform \cite{8804433:9}. Netflix, Inc. started out as a small rental company. It offered an online DVD subscriptions through the Internet. Movies were mailed to the customers in the form of DVD’s with prepaid return envelopes. Nowadays Netflix, Inc. is huge streaming platform whose content is produced in houses (Netflix Originals) or produced by other companies which Netflix  has distribution right to. With the huge shift in product delivery from postal services to online services, Netflix, Inc. needed more and more resources on the Internet and powerful software, due to the increasing demand. Consequently, the company made a decision to move its IT infrastructure from private data centres to a public cloud and replace its monolithic architecture with a microservices architecture. However, at that time, the term ``microservices" was not widely known, and the structure itself was not well-established.
Netflix, Inc. emerged as one of the first prominent companies to successfully introduce the transition from  a monolith to a cloud-based microservices architecture. This achievement was recognized in 2015 when it received the JAX Special Jury award. Nowadays , Netflix, Inc. manages and supports  various parts of its platform through over a thousand microservices.

\section{Benefits and Challenges of Microservices}

Microservices architecture numerous benefits, nevertheless due to its greater complexity than legacy systems it also meets some challenges:
\begin{itemize}
\item As the number of subservices grows so does the complexity of managing and maintaining the data consistency. The first problem is encountered at the beginning of creating system. Software architect has to find appropriate boundaries of the a subsystem. The whole business requirements have to be broken down into specific domains and the microservices that are sized adequately are supposed to be created. Unfortunately the whole process is extremely difficult to achieve.
\item There is also difficulty in testing the whole system. In addition to testing individual services independently, the service integration and interdependencies should also be considered during creating a end-to-end test plan.
\item Microservices standards allow subsystems to make subsystems using different technologies. It can cause many problems, starting from integrating microservices to use the same libraries for common operations and  finishing with transition to the maintenance mode. The advantages acquired from technical diversity may quickly get outweighed by increased maintenance costs,  generated by the necessity to arrange a  maintenance team, composed of developers who are knowledgeable about whole the technology stack. They have to be aware of the entire stack in order not to make  any breaking change in the functionality that other services depend on.
\end{itemize}
However, most of the challenges related to the microservices are around the necessity to share the business data and information between subsystems. All of that ought to be solved  with a good communication implementation, which will be discussed in the next chapter.

\section{Cloud and contenerization}
At the beginning  of  this section, one can find   brief descriptions of concepts followed by detailed analysis  further in the section subject.
\subsection{Containerization }
Containerization is a method of virtualization that operates at the application level. It allows for the creation of multiple isolated instances within a single operating system kernel. These instances are known as containers, which serve as self-contained units that pack an application’s code, runtime, system tools, libraries, and configurations into a single entity. Containers visualize CPU, memory, storage, and network resources at the operating system level, creating a segregated environment where developers can interact with the OS independently from other applications and environments. Containers share a common kernel, which is installed on the underlying hardware.

A container images serve a fundamental building block. It is a file that contains all the necessary components to run an application within a container. The image includes the application’s code, dependencies, libraries, system tools, and configurations. Images construction ,and creation is based on the configuration files, where there are specified steps required to build an image in the container instance.

\begin{figure}[h]
\centering
  \includegraphics[width=0.7\textwidth]{container.png}
\caption{Container vs Casual}
\label{fig1}
\end{figure}
\subsubsection{Docker}
Docker is a commonly used containerization platform. Currently is the most widely adopted open-source container format. It provides an additional layer of abstraction and automation for the container management. It simplifies the process of creating, deploying, and running applications within containers. Docker offers the ``docker compose" tool helping  to configure and run applications made up of multiple containers. For the docker users it provides an ecosystem of pre-build container images available through the internet on the Docker Hub website. It provides developers with the convenient way of reuse the existing solutions again.

\subsection{Orchestration}
The process of managing and arranging containers to support applications is known as a container orchestration. It is fully managed by container orchestration tools. These tools provide the necessary mechanisms to deploy, scale, manage, and monitor containerized applications. These tools help automate tasks such as container deployment, load balancing, service discovery, scaling, and fault tolerance, making it easier to manage complex containerized environments efficiently. Some widely used open-source container orchestration tools include Kubernetes, Docker Swarm, and LXC.
\begin{figure}[h]
\centering
  \includegraphics[width=0.7\textwidth]{orche.png}
\caption{Container orchestrator}
\label{fig1}
\end{figure}
\subsubsection{Kubernetess}
Kubernetes (known as K8S) is an open-source platform designed to automate the deployment, scaling, and management of containerized applications Kubernetess organizes containers that form an application into cohesive units, providing the easy way to manage complex system. Kubernetes is based on a  Google’s  fifteen year  extensive experience  in running  production workloads having  incorporated valuable insights and industry best practices gathered from the community.
\subsection{Continuous delivery}
Continuous Delivery is a software concept that enables the demand deployment of a software to any native environment. It enhances the delivery of software life circle to be automated. It leverages techniques like Continuous Integration and Continuous Deployment. 
\subsection{Microservices in cloud computing}
In recent years cloud computing gained the interest and trust of many researches and industries. This is a growing paradigm which had a big impact on the microsevices implementation. Currently on the market there are many cloud services providers such as Microsoft Azure, Amazon Web Services (AWS), Google Cloud Platform (GCP), IBM Cloud, and Kamatera. The usage of containers in the cloud makes microservices development and deployment more agile \cite{vayghan2019kubernetes:10}. Microservices are abstracted,  which means that they can be run on any operating system located in the public cloud, on premises or in the virtual hypervisor. They can be also migrated back from a cloud to the on-premises and back. Containers are a perfect solution for the deployment of microservices. They can be launched in a second, so redeployment of any failure or migration can be done rapidly. It helps to scale quickly to meet current demands. The entire microservice application can be deployed as a cluster using a orchestrator.

In the security aspect, using the same host kernel for different containers makes it more possible for attackers to gain  an unauthorized access to containers \cite{https://doi.org/10.1002/cpe.4436:11}. The containers which rely on the underlying operating system’s kernel provide the resources isolation. If an attacker manages to exploit the vulnerability in the shared kernel, they may gain an unauthorized access to the host system and potentially compromise all containers running on that host. It is called the ``container escape". Container technologies like Docker and Kubernetes have implemented security measures to mitigate these risks. 

In the software development aspect, cloud providers offer  various of functionalities that can significantly help and optimize the programming processes. They offer the integration services such as Azure Logic Apps which allow to integrate various applications and services. This enables data synchronization between applications, event monitoring, and automated responses to changes \cite{Ecfan:13}.

They offer the cloud databases like Amazon RDS, Azure Cosmos DB, or Google Cloud Firestore  which are flexible and scalable data storage solutions. These solutions offer advanced replication, data backup, and compliance management features \cite{DBS-060:18}.

Cloud networking services empower researchers to build sophisticated, distributed application architectures. Services such as AWS Virtual Private Cloud (VPC), Azure Virtual Network, or Google Cloud Virtual Private Cloud (VPC) allow developers to create isolated networks, manage network traffic, implement advanced security measures, and establish secure connections between different application components \cite{CloudComputing:15}. 

Cloud AI services deliver advanced tools for data analysis, image recognition, natural language processing, and other AI applications. Examples include Azure Cognitive Services, Google Cloud AI Platform, or AWS AI/ML Services. Researchers can leverage pre-trained AI models and algorithms to enrich their applications with intelligent capabilities such as facial recognition, language translation, and sentiment analysis \cite{Akter2022:17}. 

Cloud monitoring and analytics services enable data collection, processing, and analysis of telemetry from various application components. Services like AWS CloudWatch, Azure Monitor, or Google Cloud Monitoring allow developers to track application performance, identify issues, and optimize its operation \cite{LU201992:16}.

Cloud providers also offer  the services which are responsible for the message and event communication between subsystems. One of  them  is Azure Service bus which will be discussed  and used in the communication survey in  the next chapters.

\chapter{Communication}
This chapter will focus on analysis of a problem related to the performed experiments. The conducted research is aimed at demonstrating the effectiveness of a given technology in general terms and the functioning of the entire system.

\section{The role of communication between microservices in the overall perception of a system}
The communication between particular subsystems plays a significant role in functionality of  the entire  system. The communication is used for the following aims: 
\begin{description}
  \item[\textbf{Checks system coherence}] \hfill \\
Maintaining  the distributed system could be challenging because each subsystem can be written  in a  different time, by various developers and applied by various programming languages. The subsystems exchanges information and validates data again according to the previously predefined rules, to ensure that all the subservices operate within the specified constraints. The validation process checks the consistency of the data and cross-services dependencies and correlations  which guarantees the system coherence.
\item[\textbf{Database translations integrity}] \hfill \\
Maintaining the data consistency can be also a challenger to the distributed system. From the definition of microservices, each microservice should have separate instance of database. Even if each of the systems, performs a different operation, it could operate on the same set of data. In this situation if the data is modified by one system, the modifying system should notify other systems to update  their  databases  considering  a  conducted changes.

\item [\textbf{Collaboration of tasks synchronization}]\hfill \\
Referring to the genesis of microservices architecture, the system is composed of  particular services where each subsystem is responsible for a  single functionality. The whole system collaborates to fulfil the business processes that span across different domains. Communication between them enables the opportunity to work together seamlessly to deliver complex business functionalities. Very often there is a necessity to exchange data in order to perform respective tasks. Communication between microservices plays a significant role in facilitating task synchronization by enabling the exchange of control signals, status updates, and coordination messages among the involved subservices.  Microservices can share the status of updates and progress information during the task execution, enabling other subservices to take appropriate action based on the status. It enables to have real-time transparency, allowing better monitoring and decision-making.

\item [\textbf{Database translations integrity}]\hfill \\
Maintaining the data consistency can be also a challenger to the distributed system. From the definition of microservices, each microservice should have separate instance of database. Even if each of the systems, performs a different operation, it could operate on the same set of data. In this situation if the data is modified by one system, the modifying system should notify other systems to update  their  databases  considering  a  conducted changes.
\item \textbf{Fault tolerance}\\
Communication between microservices plays a considerable role in achieving  an effective  fault tolerance and robust exception handling mechanisms. Microservices are commonly deployed independently and errors could occur only in a separate subsystem. There are various reasons why the errors are made. The main ones include the service unavailability, because of a cloud provider and network disruptions. Microservices can attempt to execute failed operation again providing a change for the success.  They can implement the backoff mechanism,  which can manage the time intervals between attempts simultaneously reducing the time of load of the system and allowing the recovery of  an unavailable system. Additionally, communication enables microservices to implement circuit breakers, which  can detect and prevent further calls to a failing service,  consequently avoiding cascading failures and improving system stability. This isolation enhances the resilience and stability of the microservices architecture.

\item [\textbf{Exception Handling}] \hfill \\
Exception handling is a crucial aspect of any software system. It coordinates the exception handling across multiple microservices. The communication role in the exception handling in the distributed architecture is propagation the exception in- formation to other relevant services to share the awareness of an error. When an exception occurs in one microservice, it may have implications for related or dependent services It ensures that the exception was properly handled and prevented from being ignored or lost.
Communication also enables to gain the the insides from the exception properly, for example by sending it to the proper subservice which is responsible for monitoring and collection of system insides. It helps to centralize logging system and monitoring tools. This       can result in  a fast system administrator and developers’ reaction, to repair the system failure.

\item \textbf{Scalability}\hfill\\
Scalability is main requirement to create modern, efficient software system. Commu- nication between microservices plays a crucial role in achieving scalable architecture.
Communication enables the horizontal scaling by sharing the information by sub- systems about their availability and capacity  simultaneously allowing the system to adapt and distribute the processes dynamically and  efficiently.  The system can handle higher volumes of requests. Communication supports the concept of elasticity in microservices, which refers to the ability of the  system to scale up and down, automatically based on the demand. By means of communication the  system can monitor the resources usage (such as network bandwidth, CPU and memory usage) and adjust their capacity dynamically. The dynamic scaling helps the efficient utilization of available resources and optimize resources allocation. It also  helps  to prevent bottlenecks.

\item [\textbf{Security}]\hfill\\
Security is crucial element in all the software systems. Communication plays a significant role in securing systems in microservices architecture.  Communication in microservices exposes them to the risk that send message could be intercepted and be able for thrives to infer the business logic operations. Microservices are commonly deployed in in many distributed containers so the data  so it is a potential threat to steal data from one of them. 
However the communication process can be under various security mechanisms.
Implementing the security on communication system can prevent the exposing the malicious process when one of subsystems is attacked.
Gegick and Barnum 73 proposed that only the minimum necessary rights should be assigned to asubject that requests access to a resource and should be in effect for the shortest duration necessary \cite{https://doi.org/10.1002/cpe.4436:11}. 
Communication enforces the secure of communication protocols using a network-level security . Microservices can communicate over the secure channels which uses the encryption protocols (for example: Transport Layer Security (TLS) and Secure Sockets Layer (SSL)).
The encryption makes the communication secure the sensitive data from eavesdropping, tampering, or interception. 
\\
To protect data during the communication, there could be implemented the data encryption,  that utilizes shared key and public key encryption. The data can be encrypted by for example Advanced Encryption Standard (AES) as hared key encryption and RSA encryption algorithm as public key encryption scheme.
There is possibility to implement the Authorization and Authentication  through the communication. Microservices can exchange authentication tokens or credentials to verify the identity of the communicating subsystems. 
Thanks to the authorization process, there can be implemented additional role management. Role-based access control (RBAC) or attribute-based access control (ABAC), can limit the right to perform specific action only for selected system users. 
\end{description}

\section{Communication Patterns }
In microservices architecture there are a few available communication patterns. The system architect is responsible for analyzing the advantages and disadvantages of each pattern. This evaluation process is crucial in order to make an informed decision and choose the most suitable communication pattern for the specific scenario of the system. Thanks to considering the pros and cons of each pattern, the architect can ensure effective and efficient communication between the services in the system. Ultimately, the chosen communication pattern will play a considerable role in determining the overall performance and functionality of the application.

\subsection{Synchronous}
Synchronous communication refers to a communication pattern where services interact by exchanging messages and wait for a timely response before proceeding further. In this approach, a service initiates a request to another service and waits for the response, blocking its execution until a reply is received. However it is possible to asynchronous interactions using synchronous technologies. Client services instead of waiting for the request to be completed, can implement the pattern like pooling in separate thread to check the service for completion in some period of time. The examples of synchronous communication protocols are as follows:
\begin{itemize}
  \item Hypertext Transfer Protocol (HTTP),
  \item Transmission Control Protocol (TCP),
  \item Remote Procedure Call (RPC),
  \item Simple Object Access Protocol (SOAP).
\end{itemize}

\begin{figure}[h]
\centering
  \includegraphics[width=0.7\textwidth]{communication.png}
\caption{Synchronous communication diagram}
\label{fig1}
\end{figure}

\subsection{Asynchronous}
Asynchronous communication refers to a communication pattern where services interact without requiring immediate and direct response. In this approach, a service sends a message or request to another service and continues its execution without waiting for a response. The receiving service processes the message independently and may respond at a later time or not at all. \\

The asynchronous communication usually is  carried out  by implementing the message broker. Below there is a description of used terms in following communication patterns:
\begin{description}
\item \textbf{Message Broker}\\
Message broker is a piece of  the software which facilitates a data queue that connects the Producer and Consumer services.  
\item \textbf{Producer}\\
Application which is  responsible for sending or even also generating messages. It sends data directly to the message broker. In publish-subscribe pattern they are called publishers.  
\item \textbf{Consumer}\\
Application which consumes the data from the message broker. In the  published/subscribed pattern they are called subscribers
\item \textbf{Message}\\
Message is the objects sent by producer to message broker. Message is composed by a header (the metadata used for the message indication or security information) and body. 
\item \textbf{Queue/topic}\\
A directory where messages are stored.
\end{description}
The message could be consumed from the message broker by single or multiple Consumers. If a consumer wants to send  a response after processing  the data, it can sent  the message back to the message broker which will be subsequently caught by publisher system. \\
The most popular protocols for the Asynchronous Communication are
   \begin{itemize}
  \item Message Queuing Telemetry Transport (MQTT),
  \item Advanced Message Queuing Protocol (AMQP),
  \item Apache Kafka,
  \item Java Message Service (JMS),
  \item WebSockets.
\end{itemize}
\begin{figure}[h]
\centering
  \includegraphics[width=0.7\textwidth]{communication.png}
\caption{Asynchronous communication diagram}
\label{fig1}
\end{figure}
\section {Available technologies}
Currently there is a huge diversity of different technologies available on the market   which are responsible for the connection of multiple subsystems. All of the commonly used technologies are based on the communication using the protocols listed above.
\subsubsection{Synchronous}
\begin{description}
  \item Hypertext Transfer Protocol (HTTP)
  \begin{itemize}
    \item RESTful
     \item GraphQL
         \item Azure Service Bus.
      \end{itemize}
  \item Transmission Control Protocol (TCP)
   \begin{itemize}
    \item RMI
     \item gRPC 
      \end{itemize}
  \item Remote Procedure Call (RPC)
   \begin{itemize}
    \item gRPC
      \end{itemize}
  \item Simple Object Access Protocol (SOAP)
   \begin{itemize}
    \item Apache CXF 
     \item WCF  
      \end{itemize}
\end{description}
\subsubsection{Asynchronous}
   \begin{description}
    \item Message Queuing Telemetry Transport (MQTT)
     \begin{itemize}
    \item Eclipse Paho
      \end{itemize}
  \item Advanced Message Queuing Protocol (AMQP)
       \begin{itemize}
    \item RabbitMQ
    \item Azure Service Bus
      \end{itemize}
      
  \item Apache Kafka
       \begin{itemize}
    \item Kafka Streams
     \item Confluent Platform
      \end{itemize}
  \item Java Message Service (JMS)
       \begin{itemize}
    \item Apache ActiveMQ
     \item Apache IBM MQ
      \end{itemize}
  	\item WebSockets  
       \begin{itemize}
    \item Socket.IO
      \item SignalR
        \item Azure Service Bus
      \end{itemize}
   
   \end{description}
\section{Communication patterns used in the scope of the experiments}
\subsection{Azure Service Bus}
Azure bus service platform-as-a-service fully managed enterprise message broker with message queues and publish-subscribe topics on the Azure Cloud. Topic and queues uses the same mechanism for the producer however their process by consumer differs in significant way.
\begin{description}
\item[\textbf{Queue}] \hfill \\
Messages are ordered in queue and timestamped with arrival time. It provides the First In, First Out (FIFO) message delivery to one or more competative customers.  Service keeps messages until they have been reported by client as accepted. Queue usually is used as a point-to-point communication, because each message can be processed only by one customer. 
\cite{11}
\item[\textbf{Topic}] \hfill \\
Topic functionality in reference to queue, is extended by possibility of having multiple subscribers which are listening to it.  It is suitable for the publish/subscribe pattern which is useful for scaling huge number of recipients. Each message is available for each client who is subscribing to the topic. The message is deleted after every subscriber has processed the message.  \cite{11} Topics can possess multiple properties that clients can utilize for filtering, whereas queues do not implement filtration options.
\item[\textbf{Subscription}] \hfill \\A topic subscription, is strictly related to the topic. This is a mechanism in Azure Service Bus that allows multiple consumers to receive copies of messages sent to a topic. It functions as  a virtual queue, where each subscription acts as an independent recipient of messages. When a message is sent to the topic, it is automatically forwarded to all associated subscriptions.
\end{description}

\subsubsection{Formats}
The messages could be constructed in following formats:  JSON, XML, Apache Avro, Plain Text. 

\subsubsection{Protocols}
The messages is Azure Service Bus can be send by following protocols:
AMQP 1.0/1.1 (Advanced Message Queuing Protocol), MQTT 3.1 (MQ Telemetry Transport), OpenWire 2, 0MQ 2, STOMP 1.2, or HTTP 1.1. The Advanced Message Queuing Protocol is default protocol used by Azure Service bus.

\subsection{RabbitMQ}
RabbitMq is an  open source message broker which can be deployed in clustered configurations in any environment to meet high availability and throughput needs.
RabbitMq supports the Advanced Message Queuing Protocol(AMQP) and MQ Telemetry Transport (MQTT). Advanced Message Queuing Protocol is an programmable protocol which implies that entities and routing schemes are primarily defined by applications themselves, rather than by a broker administrator. Accordingly, provision is made for protocol operations that declare queues and exchanges, define bindings between them, subscribe to queues and so on. [ ref {https://www.rabbitmq.com/tutorials/amqp-concepts.html]

The messages published by publisher are not directly transferred to the queue, they are transfered to the exchange. Exhchange is responsible for routing messages to different queue, using binding, which is a link between a queue and an exchange, and routing keys, which is an message attribute added to the message header.

\paragraph{Exchanges Types}\mbox{} \\
Exchanges take message and route into zero or more queues, depending on the exchange type and bindings.
\begin{description}
\item[\textbf{Direct exchange}] \hfill \\
It uses the message routing key to transport messages into the single queue. If the message routing key does not match any binding key, the message is discard.
\item[\textbf{Default exchange}] \hfill \\
A default exchange is an direct exchange with no name, pre-declared by the broker.  It has one particular feature that makes it useful for simple applications: every queue created is automatically bound to it using a routing key that matches the queue name.
For instance, if a queue is declared with the name "search-indexing-online," the AMQP 0-9-1 broker will automatically bind it to the default exchange using "search-indexing-online" as the routing key. As a result, any message published to the default exchange with the routing key "search-indexing-online" will be routed to the queue "search-indexing-online." 
\item[\textbf{Topic exchange}] \hfill \\
It is similar to the direct exchange however topic exchange instead of using fixed routing key, uses wildcards. The message is routed to one or many queues, basing on a matching between a message routing key and pattern. A routing pattern of “university.*.*.technology” only match routing keys where the first word is “university" and the fourth word is “technology”.
\item[\textbf{Fanout exchange}] \hfill \\
Fanout exchange routes message to all the queues bounded to it, ignoring the routing key. It is ideal for the broadcast routing of messages. The exemplary usage of this exchange is the system where the same messages should be catch by the mobile application and web application or group chats where messages are distrubibuted between participants. 
\item[\textbf{Header exchange}] \hfill \\
Header exchange uses routing on multiple attributes that are more easily expressed as message header than as a routing key. It is similar to the topic exchange however it uses the header attribute instead of routing key, which is here ignored. Specific argument termed “x-match” indicates whether all headers must match or only one. The headers can be build not only with string but also with types such as integers or hashes. 
\end{description}
 \subsection{REST API}
REST is an acronym  which stands for Representational State Transfer. An API an acronym  which stands Application Programming Interface.This is defined set of rules, commands, permissions, or protocols which allow application to interact with other applications. 
A REST API is based on representational state transfer (REST) and offers a set of guideline that software can use to communicate over the internet in order to make integration's between systems.
A RESTful API uses commands to obtain resources. Is uses existing HTTP methodologies defined by the RFC 2616 protocol (Hypertext Transfer Protocol).
Set of deffinitions related to the REST API: 
\begin{description}
\item[\textbf{Client}] \hfill \\
The client makes requests to the API in order to retrieve specific information or initiate changes within the application. This can involve the operations of fetching or submitting data.

\item[\textbf{Resource}] \hfill \\
A resource refers to any piece of information that the API can provide to the client. It can represent data entities, files, functionalities, or any other element that the client interacts with via the API.

\item[\textbf{Server}] \hfill \\
The server is a fundamental component utilized by the application to handle incoming client requests. It stores and manages the resources that the client interacts with. The server exposes an API that acts as an intermediary layer, enabling clients to communicate with the application's functionalities while maintaining controlled access to the underlying database content.

\item[\textbf{Endpoint}] \hfill \\
An endpoint is a specific URL (Uniform Resource Locator) that the client uses to send requests to the server's API. Each endpoint corresponds to a distinct resource or functionality within the Server.

\item[\textbf{HTTP Methods}] \hfill \\
HTTP methods, such as POST, GET, PUT and DELETE, to perform create, retrieve, update, delete operations, commonly known as CRUD respectively. They define the action to be taken when making requests to specific API endpoints.

\item[\textbf{Data Format}] \hfill \\
APIs use standardized data formats like JSON (JavaScript Object Notation) or XML (eXtensible Markup Language) to structure and transmit data between the client and the server.

\item[\textbf{Authentication and Security}] \hfill \\
APIs often employ authentication mechanisms, such as API keys or OAuth tokens, to verify the identity of clients before granting access. The credentials are send over the http request defined in header.

\end{description}

\chapter{Implementation}
This chapter provides details about the use-case application that has been implemented in order to evaluate the impact technology to the communication between microservices. There is included the brief description of the system architecture and the functionalites which are served by each microservice in order to conduct experiments. Due to necessity of customize implementation for different experiments, information related to the exact implementation of the functionality can be found under \nameref{chap:experiments} chapter.

\section{Application}
A system in microservice architecture has been implemented, in order to simulate a real traffic between subsystems. The goal is to fetch messages produced by the producer application from clients applications. This simulation is essential for evaluating the system's behavior under different conditions, ensuring its reliability, and fine-tuning performance. The objective is to efficiently fetch messages generated by the producer application.The whole system is implemented in the .NET 6 framework..NET due to fact that is cross-platform framework, is suitable solution for building microservices, because it can be run on various operating systems, enhancing portability and flexibility. It offers powerful tools for building WEB API's and multiple libraries for implementing the integration with various external services. It is crucial for integration with RabbitMQ message broker and Azure services. Each microservice is deployed as a single container on the docker local environment.
\subsection{Architecture}
The project is a microservices-based application developed in C\#, where each microservice is implemented as a separate ASP.NET Core application using .NET 6. The application is designed to provide a scalable and modular architecture, allowing independent development and deployment of each microservice. 

Containers ordinarily get their own private network that is separate to the host stack. However in order to use inter-container networking to perform communication between them, containers are allowed to share host's network stack. It means that they are allowed to access the host machine's localhost instead  of the container's host itself. 
 
The figure BLABLA provides an overview of data flow in whole the system. Once the data is collected and processed by the publisher application, it is resend to the particular data stores. Then the data is catch by client applications and send via websocket to the virtual machine over the websocket. 

Whole system is consisted of.......

\subsection{Publisher API}
Producer application is a microservice which is provided with a set of data.  In reference to the microservices principles, there is no option to share common database within subsystems. The primary objective of the application is to process and services data efficiently with clients, using RESTful and asynchronous communication methods.  Producer dispatches data to designated message brokers: RabbitMq broker, Azure Service Broker and saves it in the local database.
When RESTClient microservice request access to previously processed data Producer Application retrieving  data from the database and delivers it synchronously to the clients in response to HTTP requests.
The producer functionalities are invoked by the HTTP Request to following endpoints: 
\begin{description}[style=nextline, font=\normalfont\textbf]
  \item [HTTP POST] \textnormal{\texttt{host/api/publisher/produce/rabbitMQ/direct}}
  Following endpoint while invoked, starts the process of publishing set of data to the RabbitMQ direct exchange with pre-configured binding.
  \item [HTTP POST] \textnormal{\texttt{host/api/publisher/produce/rabbitMQ/fanout}}
  Following endpoint while invoked, starts the process of publishing set of data to the RabbitMQ fanout exchange with pre-configured bindings.


  \item [HTTP POST \texttt{host/api/publisher/produce/azureServiceBusQueue}]
  Following endpoint while invoked, starts the process of publishing set of data to the Azure Service Bus Queue.

  \item [HTTP POST \texttt{host/api/publisher/produce/azureServiceBusTopic}]
  Following endpoint while invoked, starts the process of publishing set of data to the Azure Service Bus Topic.

  \item [HTTP POST \texttt{host/api/publisher/produce/database}]
  Following endpoint while invoked, starts saving data into the local database. The aim of the process is related to synchronous REST communication. Due to the fact that with REST, data by client applications is received directly from the Producer API, the Producer API must have a place where the data will be stored until the REST Client API requests it.
\end{description}
Producer application has separate controller for REST Communication with REST Client API. 
\begin{description}[style=nextline, font=\normalfont\textbf]
  \item [HTTP GET \texttt{host/api/publisher/RESTDataProvider/GetById/{id}}]
  REST Client API asks the Producer to get single data by calling the following endpoint, including the objectId in the request params. The Producer retrieves the object from the database and returns it in the response to the request.

  \item [HTTP GET \texttt{host/api/publisher/RESTDataProvider/GetAll}]
  REST Client API requests the Producer to get all produced data by calling the following endpoint. The Producer retrieves all the objects from the database and returns them as a list in the response to the request.
\end{description}

Figure no [] provides the architecture schema of Producer API. The Producer API is deployed as a solitary container within the Docker localhost environment.

\subsection{REST Client API}
Rest client API is an application is built on ASP.NET Core technology, to retrieve data from the Producer API over the HTTP protocol using REST API principles.The application serves as a data consumer and interacts with Producer API to obtain required data in synchronous manner. Rest Client API sends HTTP GET requests directly to the Producer API. Upon a successful response from the Producer API, the application receives the requested data.  In case of any error during the API call, application handles the exception and returns it with a suitable status code. In order to simulate multiple consumers traffic for experiment no 2, the instance of  REST Client API, has been deployed 5 times in form of seperated docker containers.

The Rest Client API has been designed to with the intention of enabling communication with external clients using the HTTP protocol. To obtain the interaction, the following endpoints have been made:
\begin{description}[style=nextline, font=\normalfont\textbf]
\item [HTTP GET \texttt{host/api/RestClient/{id}}]
     It initializes the process of obtaining single  data from Producer API. As a response application returns single message.
\item [HTTP GET \texttt{host/api/RestClient/all}]
  It initializes the process of obtaining all produced data from Producer API. As a response, application returns list of messages.
\end{description}
 The REST Client API is deployed as a solitary container within the Docker localhost environment.
\subsection{RabbitMQ Consumer APIs}
RabbitMQ Consumer API is an application built on ASP.NET Core technology, to retrieve data produced by Producer Api using RabbitMQ message broker over the AMQP protocol. 

The application serves as consumer application, which is representation for the asynchronous communication. It does not interact with Producer API directly, but rather they communicate via an intermediary known as message broker. RabbitMQ message broker is deployed as a separate container on the local environment, using Docker image for RabbitMQ. The RabbitMQ Docker image is based on the official RabbitMQ image available on Docker Hub, and it is created using a Dockerfile. The Dockerfile defines the instructions to build the image, including the base image, environment setup, and any additional configurations needed for RabbitMQ.

Once the RabbitMQ Consumer API is in the need of data, it makes call to the message broker with pre-configured binding to pick it up.  
For the purpose of conducting two different experiments with the use of the RabbitMQ message broker, two versions of the RabbitMQ Consumer API application were created. The versions differ in the type of exchange they refer to.
\subsubsection{RabbitMQ Concumer Direct Exchange API}\
For the experiment no. 1 [ref] where one consumer gets data, the RabbitMQ Consumer API collects data directly from direct exchange.
Referring to the definitions presented in ref [], direct exchange sends data directly to one queue specified in bindings.
The RabbitMQ Consumer Direct Exchange API has been designed to with the intention of enabling communication with external clients using the HTTP protocol. To obtain the interaction, the following endpoints have been made;
\begin{description}[style=nextline, font=\normalfont\textbf]
\item [HTTP GET \texttt{host/api/rabbitMQConsumer/direct/single}]
  It initializes the process of picking up single message from RabbitMQ broker. As a response application returns single message.
\item [HTTP GET \texttt{host/api/rabbitMQConsumer/direct/all}]
It initializes the process of picking up all available messages from RabbitMQ broker. As a response, application returns list of messages.
\end{description}

\subsubsection{RabbitMQ Consumer Fanout Exchange API}
For the experiment no. 2 [ref] where multiple consumers are gets data simultaneously, the RabbitMQ consumer API, collects data from Fanout Exchange. 
Since RabbitMQ only supports queuing logic, messages are enqueued and dequeued in the First-In First-Out manner. For the multiple consumers scenario, there is an need of enqueue messages to the multiple queues, each for one consumer. The fanout exchange is suitable in this case, because It routes messages to all of the queues that are bound to it. 

The RabbitMQ Consumer Fanout Exchange API has been designed to with the intention of enabling communication with external clients using the HTTP protocol. To obtain the interaction, the following endpoints have been made:
\begin{description}[style=nextline, font=\normalfont\textbf]
\item [HTTP GET \texttt{host/api/rabbitMQConsumer/fanout/single}]
  It initializes the process of picking up single message from RabbitMQ broker. As a response application returns single message.
\item [HTTP GET \texttt{host/api/rabbitMQConsumer/fanout/all}]
It initializes the process of picking up all available messages from RabbitMQ broker. As a response, application returns list of messages.
\end{description}


\subsection{Azure Service Bus APIs}
Azure Service Bus Queue Consumer API is an application built on ASP.NET Core technology, to retrieve data produced by Producer Api using Azure Service Bus cloud message broker over the AMQP protocol. 

Referring to the possibilities offered by Azure, and the lack of recommendations related to the selection of the appropriate solution by Microsoft, the process of collecting data from both queues and topics has been implemented. Each pattern is implemented by the seperate microservice.
\subsubsection{Azure Service Bus Queue API}

Azure Service Bus Queue Consumer API substitute of RabbitMQ Consumer API in the context of messaging systems. It also collects data from queue, using pattern First-in-First-out however Azure Service Bus is an cloud-base message broker as opposed to the traditional local deployment of RabbitMQ. Once the Azure Service Bus Consumer API is in the need of data, it makes call to the message broker with pre-configured queue binding.

Following API is used in the experiment no. 1 ref[]. In the reference to the definitions provided in ref[], the queue is often used to point-to-point communication, because of the mentioned first-in first-out manner. It is suitable for single consumer scenario. 

The Azure Service Bus Queue Consumer API has been designed to with the intention of enabling communication with external clients using the HTTP protocol. To obtain the interaction, the following endpoints have been made
following endpoints: 
\begin{description}[style=nextline, font=\normalfont\textbf]
\item [HTTP GET \texttt{host/api/asbConsumer/queue/single}]
  It initializes the process of picking up single message from Azure Service Bus broker. As a response application returns single message.
\item [HTTP GET \texttt{host/api/asbConsumer/queue/single}]
It initializes the process of picking up all available messages from RabbitMQ broker. As a response, application returns list of messages.

\end{description}
    
\subsubsection{Azure Service Bus Topic API}
In Experiment No. 2, the following API is utilized: ref[].  
The definitions refereed in  ref[], indicate that the topics are appropriate for multi-consumer scenario. This is because a topic facilitates the sharing of messages with all subscribers who are listeing to the particular topic.

 To implement this functionality, five docker containers of Azure Service Bus Topic API have been deployed. Each container differs from other based on the specific subscription to which it is connected in the Azure Service Bus Topic.
 
When the Azure Service Bus Consumer API requires data, it initializes a call to the message broker under implemented subscription. This subscription has a pre-configured binding to the appropriate topic, allowing the API to retrieve the data.

The Azure Service Bus Consumer API has been designed to with the intention of enabling communication with external clients using the HTTP protocol. To obtain the interaction, the following endpoints have been made: 
\begin{description}[style=nextline, font=\normalfont\textbf]
\item [HTTP GET \texttt{host/api/asbConsumer/topic/single}]
  It initializes the process of picking up single message from RabbitMQ broker. As a response application returns single message.
\item [HTTP GET \texttt{host/api/asbConsumer/topic/all}]
It initializes the process of picking up all available messages from RabbitMQ broker. As a response, application returns list of messages.
\end{description}
\subsection{Architecture}

\chapter{Experiments} 
\label{chap:experiments}
The "Experiments" chapter provides the description of 3 different scenarios, explanation how selected communication pattern could be implemented in the Web Application source code, what difficulties and limitation could be met and the analysis of the metrics collected during performing the experiments. 
Each experiment is aimed to found the advantages and disadvantages of using the selected communication pattern for a specific use case.

\section{Metrics taken into account during the analysis}

Metrics for following experiment has been collected using The Apache JMeter™ tool. This is an open software toll, based on Java, to  perform load and functional test. It helps to simulate multiple scenarios such as heavy load on a server to analyse overall performance under different load conditions. It helped to get insides of request latency, load time, throughput, minimum and maximum of response, count of errors, size of objects and general experiment time. Thanks to that, there was possibility to analyse the results in clear way. It has generated  diagrams which show in a transparent way the data acquisition process. 

\begin{itemize}
    \item \textbf{Latency} \\
    Latency refers to the time difference between when a request is sent and the moment the response begins to be received.
The average latency is given by:
\[
\text{Average latency} = \frac{\text{Sum of latencies}}{\text{Total number of events}}
\]
    \item \textbf{Connect Time} \\
     Connect time defines the time taken to establish the TCP connection between the client and the server using TCP Handshake. This process involves the initial steps of a three-way handshake: the client sends a SYN packet to the server, the server responds with a SYN-ACK packet, and finally, the client acknowledges the server's response with an ACK packet. Whereas TCP Handshake is successful, then the client can send further requests. If not, the client can't talk to the server. the server might not be available, couse of beeing overwhelmed with other requests, or there could be network issues preventing the handshake from completing,

    \item \textbf{Average response time} \\
    Response time signifies the time difference between when a request is sent and when the complete response is received. The response time should be always higher than latency. The larger file is, the larger difference between response time and latency will be.
    The average response time is given by:
\[
\text{Average response time} = \frac{\text{Sum of response times}}{\text{Total number of requests}}
\]
    \item \textbf{Throughput} \\
    Throughput denotes the total count of requests that an application can process during a specified time frame. In contrast to Latency, the higher throughput value indicates better performance and system capacity to handle multiple requests concurrently. In the metrics below, throughput is measured within one second.
    Thought is calculated by following formula: \\
\[
\text{Throughput (RPS)} = \frac{\text{Number of Requests}}{\text{Test Duration (in seconds)}}
\]
    \item \textbf{90\% Line (90th Percentile)} \\
    The response time below which 90\% of the samples fall,
\item \textbf{Error rate} \\
    The error rate represents the number of errors that occurred during the experiment,
 \item \textbf{standard deviation } \\   
 A standard deviation is a measure of how data is distributed in relation to the mean. Low standard deviation indicates that data is clustered around the mean. Nonetheless the high standard deviation indicates that data is more distributed. When a standard deviation is close to zero signify that data points are close to the mean. A high or low standard deviation indicates data points are respectively above or below the mean.
 The standard deviation is calculated by:
\[
\text{Standard deviation} = \sqrt{\text{Variance}}
\]
The variance is calculated by:
\[
\text{Variance} = \frac{1}{N} \sum_{i=1}^{N} (x_i - \text{Mean})^2
\]
Where:
\begin{itemize}[label=--]
    \item \(\text{Variance}\) represents the variance.
    \item \(N\) is the total number of data points.
    \item \(x_i\) represents each individual data point.
    \item \(\text{Mean}\) represents the mean (average) of the data points.
    \item \(\sum_{i=1}^{N}\) denotes the summation over all \(N\) data points.
\end{itemize}
\end{itemize}

\section{ First experiment}

"The client application wants to use the data already processed by the producer application.The data produced by the producer application is placed in various resources, depending on the communication technology (REST, RabbitMQ, Azure Service Bus) that microservices use. The producer application does not need to get information about whether the data has been received by the client. The customer receives the data when he needs it, so that he does not store it in his system unnecessarily. Data produced by producer has single consumer." 

\subsection{Key values of the scenario}
\begin{enumerate}[label=\arabic*.]
    \item \textbf{Asynchronous:} The communication between the producer application and the client application is asynchronous. The client does not wait for the data to be immediately available upon request but retrieves it at a later time.
    
    \item \textbf{Decentralized Data Placement:} The data produced by the producer application is placed in various resources, depending on the communication technology (REST, RabbitMQ, Azure Service Bus) that microservices use. This implies a decentralized approach to data storage and placement.
    
    \item \textbf{Unidirectional Communication:} The data flows from the producer to the consumer (client) in a unidirectional manner for Azure Service bus and RabbitMQ. The producer does not need to know whether the data has been received by the client.
    
    \item \textbf{On-Demand Data Consumption:} The client receives the data when it needs it, ensuring that it does not store unnecessary data locally. This efficient data consumption approach minimizes storage overhead on the client side.
    
    \item \textbf{Single Consumer:} The data produced by the producer has a single consumer, which is the client application. This indicates a one-to-one relationship between the producer and the consumer for the specific dataset being retrieved.
\end{enumerate}


The experiment was divided into two variants:
\begin{itemize}
    \item The client receives the data individually, one request for each data,
    \item The customer receives all the data available within one request;
    \end{itemize}
For each variant has been performed experiments on different amount of object: 
\begin{itemize}
    \item 1000 objects, 
    \item 300 000 objects;
    \end{itemize}
For each variant has been performed experiments on different size of object: 
\begin{itemize}
    \item UTF-8 encoded string created by joining various properties of the \texttt{joystic} object, resulting in a size of 47 bytes.
    \item -----;
    \end{itemize}

\subsection{ First experiment technical arrangement}
\label{sec:firstexperimenttechnicalarrangement}
\subsubsection{Publisher}
\label{subsec:publisherfirst}
\paragraph{Azure Service Bus Queue Publisher}\mbox{} \\
\label{asbPublisher}
Configuring the function for sending data to the Azure Service Bus was a highly intricate process. The focus while implementing the function was put on expeditiously sending considerable data packets to the Azure Service Bus. The connection with Azure Service Bus is made using Nuget package \texttt{Azure.Messaging.ServiceBus}, by creating  an object of \texttt{ServiceBusClient} and \texttt{ServiceBusSender}, using connection string and queue name. 
    The code ~\ref{lst:azurepublisherqueuesnippet} presents the process of publishing messages  to the Azure Service Bus. The publishing procedure was optimized by structuring messages into batches that conform to predefined size constraints. The utmost size of each message batch is constrained to 256 KB, and exceeding this size results in batch rejection. Prescribed maximum batch size is 256 KB, however the size of message is calculated taking into account not only the message body size, but also the headers and other message metadata. Function \texttt{TryAddMessage}, attempts to add a message to the batch, ensuring that the size of the batch does not exceed its maximum. Otherwise, function does not add the message to the batch, it sends the current batch to Azure Service Bus, disposes it , recreates new one and finally adds message to recent batch. The process is repeated in each iteration while exceeding the end of list of objects waiting to be send. 

\begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of sending messages to the queue on the Azure Service Bus}, label={lst:azurepublisherqueuesnippet}]
var serviceBusMessageBatch = await sender.CreateMessageBatchAsync();

for (int i = 0; i < message.Count; i++)
{
    var messageBytes = Encoding.UTF8.GetBytes(String.Join(",", message[i].time, message[i].axis_1, message[i].axis_2, message[i].button_1,
        message[i].button_2, message[i].id.ToString()));

    if (!serviceBusMessageBatch.TryAddMessage(new ServiceBusMessage(messageBytes)))
    {
        await sender.SendMessagesAsync(serviceBusMessageBatch);
        serviceBusMessageBatch.Dispose();
        serviceBusMessageBatch = await sender.CreateMessageBatchAsync();
        serviceBusMessageBatch.TryAddMessage(new ServiceBusMessage(messageBytes));
    }
}
await sender.SendMessagesAsync(serviceBusMessageBatch);

\end{lstlisting}
\paragraph{RabbitMQ Direct Exchange Publisher}\mbox{} \\
The process of interacting with RabbitMQ involves sending and consuming messages. To send messages, the connection to RabbitMQ is established using the Nuget package \texttt{RabbitMQ.Client}. This is achieved by creating an object of \texttt{ConnectionFactory} and \texttt{IModel}, which represents the communication channel. The connection is made to the address where the Message Broker is located. Channels are utilized to interact with RabbitMQ queues. Within a channel, a queue is declared, defining attributes such as the queue name, durability, exclusivity, and auto-deletion.
The code ~\ref{lst:rabbitsnippet} demonstrates how messages are sent to direct exchange on RabbitMQ message broker. Each message, in contrast to Azure Service Bus, is published separately to the specified exchange (default exchange) with the routing key set to predefined \texttt{\_queueName}. 

\begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of sending messages to the direct exchange on RabbitMQ}, label={lst:rabbitsnippet}]
channel.QueueDeclare(queue: _queueName,
                               durable: false,
                               exclusive: false,
                               autoDelete: false,
                               arguments: null);

foreach (Joystick Joystick in message)
{
    channel.BasicPublish(exchange: "",
                         routingKey: _queueName,
                         basicProperties: null,
                         body: Encoding.UTF8.GetBytes(String.Join(",", Joystick.time, Joystick.axis_1, Joystick.axis_2,Joystick.button_1, Joystick.button_2, Guid.NewGuid().ToString())));
}
\end{lstlisting}

\paragraph{ Representational State Transfer Publisher}\mbox{} \\
 In the context of implementing the data communication functionality through Representational State Transfer, the data is persistently stored within a designated database repository. The code ~\ref{lst:restsavedata} presents the essential steps of saving data to the database. The code begins by constructing an SQL query template for inserting data into the 'Joystics' table. The query employs parameter placeholders for each attribute, ensuring secure and parameterized database interactions to prevent SQL injection vulnerabilities. Within the loop, the code iterates through each `Joystic` object extracted from the REST communication. For each `Joystic` object, the code sets the corresponding parameter values with the attributes of the object. Upon setting the parameter values, the code executes the SQL command using `ExecuteNonQuery()`. This action inserts the data from the `Joystic` object into the database as a new record. It is noteworthy that the entire operation occurs within a single transaction, as indicated by the `BeginTransaction()` and `Commit()` methods. It helps to get better performance, than committing each row separately.  This transactional approach ensures data integrity and consistency. Either all records are inserted successfully, or none are inserted in the case of an error.
 \begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of saving all objects to the local database enginee.}, label={lst:restsavedata}]
string insertQuery = "INSERT INTO Joysticks (Time, Axis_1, Axis_2, Button_1, Button_2) VALUES (@Time, @Axis_1, @Axis_2, @Button_1, @Button_2)";

using (SQLiteCommand cmd = new SQLiteCommand(insertQuery, this.sqlite_conn))
{
    cmd.Parameters.Add(new SQLiteParameter("@Time"));
    cmd.Parameters.Add(new SQLiteParameter("@Axis_1"));
    cmd.Parameters.Add(new SQLiteParameter("@Axis_2"));
    cmd.Parameters.Add(new SQLiteParameter("@Button_1"));
    cmd.Parameters.Add(new SQLiteParameter("@Button_2"));

    using (var transaction = this.sqlite_conn.BeginTransaction())
    {
        foreach (Joystick Joystick in Joysticks)
        {
            cmd.Parameters["@Time"].Value = Joystick.time;
            cmd.Parameters["@Axis_1"].Value = Joystick.axis_1;
            cmd.Parameters["@Axis_2"].Value = Joystick.axis_2;
            cmd.Parameters["@Button_1"].Value = Joystick.button_1;
            cmd.Parameters["@Button_2"].Value = Joystick.button_2;

            cmd.ExecuteNonQuery();
        }

        transaction.Commit();
    }
}
\end{lstlisting}

\subsubsection{RabbitMQ Direct Exchange Client API}
\label{subsec:rabbitMQFirst}
\paragraph{Retrieving individual messages in a single request}\mbox{} \\
The process of consuming a single message from a direct exchange using the RabbitMQ library is shown in \ref{lst:rabbitmqconsumedirectsinglesnippet}. The procedure begins with instantiating a \texttt{ConnectionFactory} object, which encapsulates the necessary details for establishing connections to the messaging system. Once a connection is established, a communication channel is created. Within this channel, a queue is declared with specified attributes, mirroring the message-sending process.The connection is established through the IRabbitMQConnectionFactory service, maintains a singleton lifecycle within the application. This design ensures that, the connection is established once per application life time, preventing  the scenario where, each request triggers new connection to RabbitMQ. This optimalization helps enhance processing efficiency, by avoiding unncessary slowdowns.

To facilitate message retrieval, an event-based consumer is created on the communication channel. The subsequent code segment endeavors to fetch messages using the \texttt{BasicGet} method, incorporating parameters for queue name and auto-acknowledgment. Auto-acknowledgment signifies automatic marking of messages as received. When a message is retrieved, its byte-array body is transformed into a coherent string representation using UTF-8 encoding.
\begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of consuming single message in one request from RabbitMQ message broker}, label={lst:rabbitmqconsumedirectsinglesnippet}]
{
    _channel.QueueDeclare(queue: _queueName, durable: false, exclusive: false, autoDelete: false, arguments: null);
    var consumer = new EventingBasicConsumer(_channel);
    BasicGetResult result = _channel.BasicGet(_queueName, autoAck: true);
        if (result != null)
        {
            var data = Encoding.UTF8.GetString(result.Body.ToArray());
            return Ok(data);
        }
        else
        {
            return NotFound("No data available in the queue.");
        }
}
\end{lstlisting}
    
\paragraph{Retrieving all messages in a single request}\mbox{} \\
The pivotal steps involved in consuming messages from a direct exchange using the RabbitMQ library are outlined in code ~\ref{lst:rabbitmqconsumedirectallsnippet}.Likewise, in the single message retrieval approach, the code initiation involves creating instances of \texttt{ConnectionFactory} and channel objects. Subsequently, a queue is declared with specific attributes.

To accommodate the retrieved message data, a collection named \texttt{dataList} is initialized. The code employs an iterative loop mechanism to continuously retrieve messages from the designated queue. During each iteration, the \texttt{BasicGet} method is employed to retrieve a message, and an auto-acknowledgment mechanism is invoked. Upon successfully obtaining a message, its byte-array body is transformed into a coherent string using UTF-8 encoding, and subsequently added to the \texttt{dataList} collection.When no messages are retrieved, the loop ends, acknowledging the absence of additional data in the queue. 
\begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of consuming all messages in one request from RabbitMQ message broker}, label={lst:rabbitmqconsumedirectallsnippet}]
{
_channel.QueueDeclare(queue: _queueName, durable: false, exclusive: false, autoDelete: false, arguments: null);
var dataList = new List<string>(); 
    while (true)
    {
        BasicGetResult result = _channel.BasicGet(_queueName, autoAck: true);
        if (result != null)
        {
            var data = Encoding.UTF8.GetString(result.Body.ToArray());
            dataList.Add(data);
        }
        else
        {
            break;
        }
    }
}
\end{lstlisting}
\subsubsection{REST Client API}
\label{subsec:restfirst}
\paragraph{Retrieving individual messages in a single request}\mbox{} \\

The consumption of a solitary message from a producer application, employing the REST communication pattern is presented in code ~\ref{lst:restclientbysinglesnippet}. An asynchronous HTTP GET request is sent to an external Producer API endpoint to retrieve single message. The request URL is constructed using the provided message "id" parameter.
The code ~\ref{lst:restclientpublishersnippet} presents how producer catches the request and responses with taken message from database by specific id. 
Client after receive the response, reads the content of the response as a string and if the response is successful, the retrieved data is returned to requestor. 

\begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of invoking the call to the Publisher API to receive single message.}, label={lst:restclientbysinglesnippet}]
{
   var response = await _httpClient.GetAsync($"http://host.docker.internal:8080/api/publisher/RESTDataProvider/GetById/{id}");

    if (response.IsSuccessStatusCode)
        {
             var data = await response.Content.ReadAsStringAsync();
                return Ok(data);
        }
        else
        {
            return StatusCode((int)response.StatusCode);
        }
\end{lstlisting}

\begin{lstlisting} [caption={Code excerpt presenting the process of consuming all messages in one request from RabbitMQ message broker}, label={lst:restclientpublishersnippet}]
    [HttpGet("GetById/{id}")]
    public IActionResult GetById(int id)
    {
        try
        {
            var message = sqLiteRepo.GetJoystickById(id);
                return Ok(message);
        }
        catch
        {
            throw;
        }
    }
\end{lstlisting}
\paragraph{Retrieving all messages in a single request}\mbox{} \\
The process of consuming a single message from a producer application using the REST communication pattern shown in code ~\ref{lst:restclientallsnippet}.
An asynchronous HTTP GET request is sent to an external Producer API endpoint to retrieve all data.
Code ~\ref{{lst:restproducerallsnippet}} presents how producer catches the request and responses with taken messages from the database. 
Client after receive the response, reads the content of the response as a string and if the response is successful, the retrieved data is returned to requestor. 

\begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of invoking the call to the Publisher API to receive list of all messages.}, label={lst:restclientallsnippet}]
{
   var response = await _httpClient.GetAsync($"http://host.docker.internal:8080/api/publisher/RESTDataProvider/GetById/{id}");

    if (response.IsSuccessStatusCode)
        {
             var data = await response.Content.ReadAsStringAsync();
                return Ok(data);
        }
        else
        {
            return StatusCode((int)response.StatusCode);
        }
\end{lstlisting}

\begin{lstlisting} [caption={Code in C\# presenting the process of getting all messages from database.}, label={lst:restproducerallsnippet}]
    [HttpGet("GetById/{id}")]
    public IActionResult GetById(int id)
    {
        try
        {
            var message = sqLiteRepo.GetJoystickById(id);
                return Ok(message);
        }
        catch
        {
            throw;
        }
    }
\end{lstlisting}
\subsubsection{Azure Service Bus Queue Client API}
\label{subsec:AzureServiceBusFirst}
\paragraph{Retrieving individual messages in a single request}\mbox{} \\
\label{par:retriveindividualmessage}
 The connection with Azure Service Bus is made using Nuget package \\ \texttt{Azure.Messaging.ServiceBus}, by creating an object of \texttt{IMessageReceiver} using connection string and queue name. This instance facilitates the asynchronous reception of messages from a designated queue. The connection is established through the AzureServiceBusConnectionFactory service, maintains a singleton lifecycle within the application. This design ensures that, the connection is established once per application life time, preventing  the scenario where, each request triggers new connection to Azure Service Bus. This optimalization helps enhance processing efficiency, by avoiding unncessary slowdowns. The incoming message is stored as an object of type Message. The CompleteAsync method is invoked to indicate the message's successful handling. The content of the processed message's body, having been transformed from its binary representation to a UTF-8 encoded string and returned in the response of request ~\ref{lst:restproducerallsnippet}.
 
 \begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of getting all messages from database.}, label={lst:restproducerallsnippet}]
IMessageReceiver messageReceiver = azureServiceBusConnectionFactory.messageReciver;
Message message = await messageReceiver.ReceiveAsync();
await messageReceiver.CompleteAsync(message.SystemProperties.LockToken);
return Ok(Encoding.UTF8.GetString(message.Body));
\end{lstlisting}
\paragraph{Retrieving all messages in a single request}\mbox{} \\

The connection with azure service bus is estabilished in the same way as in above section  ~\ref{par:retriveindividualmessage}. Function  ~\ref{lst:azureserviceallsnippet} establishes a continuous loop for receiving and processing messages from an Azure Service Bus queue in batches. It utilizes a predefined batchSize to retrieve groups of messages, then decodes from their binary format to UTF-8 encoded strings and stores their contents in a list named messagesResult. The loop iterates until there are no more messages to retrieve from the queue, effectively managing the ongoing message retrieval and processing operation.To ensure the integrity of the processing operation, the code utilizes the CompleteAsync method to signal the successful handling of each message, preventing duplicates and ensuring proper management of the message queue.
\begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of getting all messages from database.}, label={lst:azureserviceallsnippet}]
int batchSize = 256;
List<string> messagesResult = new List<string>();
    while (true)
    {
        MessageReceiver messageReceiver = azureServiceBusConnectionFactory.messageReciver;
        var messages = await azureServiceBusConnectionFactory.messageReciver.ReceiveAsync(batchSize);

        if (messages.Count == 0)
            {
                break;
            }

        foreach (var message in messages)
            {
             var messageBody = Encoding.UTF8.GetString(message.Body);
            messagesResult.Add(messageBody);
            await azureServiceBusConnectionFactory.messageReciver.CompleteAsync(message.SystemProperties.LockToken);
            }
    }
\end{lstlisting}
\subsection{Experiments Results}
\subsubsection{Publisher}

\begin{itemize}
   \item \textbf{Performance}\\
    The following table \ref{tab:exp1publishermetrics} presents the results collected while sending messages to data stores, taking into consideration  the communication patterns.In order to get more insides from the experiment, the data was collected during the process of transferring 300,000 data.

\begin{table}[h]
    \centering
    \caption{Performance metrics for publishing 300 000 messages to data stores}
    \label{tab:exp1publishermetrics}
\begin{adjustbox}{width=0.8\textwidth}
\begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Technology} & \textbf{Response time (s)} & \textbf{Error rate} & \textbf{Throughput (RPS)} \\
    \hline
    Rest & 6.015 & 0 & 0.166 \\
    \hline
    RabbitMQ Queue Direct & 10.993  & 0 & 0.091 \\
    \hline
    Azure Service Bus Queue &  244.161 & 0 & 0.004 \\
    \hline
\end{tabular}
\end{adjustbox}

\end{table}
The process of saving  data to the database for the REST Communication pattern, demonstrates the lowest latency and a  response time, with values of 6.015 seconds. Sending the data to the message brokers, for both Azure Service Bus Queue and RabbitMq Queue Direct exhibit notably higher latency and response time, amounting to  244.161 seconds and 10.993 seconds, respectively.
The throughput, measured in requests per second, presents an interesting perspective. REST communication boasts a throughput of 0.34483 requests per unit time, which is notably higher than the message broker technologies. Azure Service Bus Queue and RabbitMq Queue Direct exhibit lower throughput values of 0.00421 and 0.09515 requests per unit time, respectively.
RabbitMQ proves significantly faster, exhibiting 95.604\% higher throughput when compared to data transmission in the Azure Service Bus queue.
This difference could  result  from many restrictions related to data transfer that had to be taken into account during the implementation a solution for Azure Service Bus \ref{asbPublisher}. All conditional statements had to be executed in each iteration for 300000 objects, which could remarkably slow down this process remarkably. The delay also is related to the network latency described under \ref{networklatency}.
 
All three technologies showcase a 0\% error rate, indicating robust and successful data transmission in each case. However the experiment proves that about 1000 messages was lost in the rabbitMQ queue. 

For the selected scenario, the least efficient publishing messages to Azure Service Bus. However due to the fact that the data can be received by the client, also after a long time, the  following scenario, publishing process may not slow down the system. 
\item \textbf{Implementation complexity}\\
The most significant challenges encountered during the implementation of publishing messages to Azure Service Bus. Creating an optimal approach for message publication wasn't straightforward and required multiple rounds of testing. Azure Service Bus offers a numerous packages versions and similar methods within .NET community. Additionally,  the configuration of queues necessitated a deep understanding of configuration options. In contrast, RabbitMQ publishing process is straightforward and it does not requiremessages to be batched for efficient handling. It's important to note that Azure Service Bus provides extensive features but can be more complex to use compared to RabbitMQ. On the other hand, while RabbitMQ is simpler to work with, it might not offer the same diversity of configuration options and message ordering management.
Saving messages into database,  entails the prior creatio of the database instance, repository, and tables that are suitable for storing the Joystick object. In other hand, the messages brokers (Azure Service Bus and RabbitMQ) stores object as a byte representation, allowing all objects converted to bytes to be accepted. This reduces implementation complexity when compared to using databases alongside message brokers.
\end{itemize}

\subsubsection{Consumers}

\paragraph{1 object per requests, 300 000 requests}
\subparagraph{Rest}\mbox{} \\
\label{RestExp1}
The entire experiment took 5 hours 30 minutes, involving the execution of 300,000 requests. The average response time for the experiment is 0.0064 seconds. Despite this efficiency, the maximal recorded response time reached 2.185 seconds, significantly exceeding the average response time by 34 times. Nevertheless the 99 \% of request have response time lower than 0.032 seconds.The system demonstrates an average  throughput of 15.120 requests per second. The average standard deviation stood around 0.299 second, highlights a consistent performance, though the disparity between minimum and maximum response times is substantial \ref{tab:restclientmetrics}.  
Upon scrutinizing the connection graph \ref{connectTimeRest1} and juxtaposing it with response time graph \ref{responseTimeRest1},  it can be deducted that the most of the highest response time values are strictly associated with the problem to establish TCP connection with Client API, more than the over-helmets  on the Producer side. However around  2 hours and 50 minutes of the experiment, there occurred the delay on response, which was not invoked by the connection problem. Drawing from the latency graph \ref{latencyRest1}, difference between its values and values presented response time graph \ref{responseTimeRest1} is minor, suggesting that the full response retrieval remained relatively unchallenging. 
Upon scrutinizing the connection graph \ref{connectTimeRest1} it can be deduced that the connect time was almost for all experiments near to zero. 
\begin{table}[h]
    \centering
    \caption{Performance metrics for consuming 300000 messages, single message per request from database using REST API}
    \label{tab:restclientmetrics}
    \begin{adjustbox}{width=1\textwidth}
        \begin{tabular}{|c|c|c|c|c|c|c|}
            \hline
            \textbf{Technology} & \textbf{Average Latency (s)} & \textbf{99\% Line Latency (s)} & \textbf{MIN Latency (s)} & \textbf{Max Latency (s)} & \textbf{Throughput (RPS)} & \textbf{Std. Dev.} \\
            \hline
            REST & 0.064 & 0.145 & 0.032 & 2.185  & 15.120 & 0.299 \\
            \hline
        \end{tabular}
    \end{adjustbox}
\end{table}
Thought the experiment no error has been encountered, affirming the robustness of the system.
%Connect Time
 \begin{figure}[h]
\centering
  \includegraphics[width=1\textwidth]{Experiments/Experiment 1/REST/connectime.png}
\caption{The connect time diagram for an experiment o on REST communication pattern,  with single consumer and 300000 of request.}
\label{connectTimeRest1}
\end{figure}


% Latency
 \begin{figure}
\centering
  \includegraphics[width=1\textwidth]{Experiments/Experiment 1/REST/responselatencies.png}
\caption{The response latency diagram for an experiment on REST communication pattern,  with single consumer and 300000 of request. }
\label{latencyRest1}
\end{figure}

% ResonspeTime
 \begin{figure}[h]
\centering
  \includegraphics[width=1\textwidth]{Experiments/Experiment 1/REST/responsetime.png}
\caption{The response time diagram for an experiment on REST communication pattern,  with 5 connected clients and 50 thousands of request. }
\label{responseTimeRest1}
\end{figure}


\subparagraph{RabbitMQ}\mbox{} \\
The entire experiment 31 minutes, involving the execution of 300,000 requests. The average response time for the experiment is 0.005 seconds. Despite this efficiency, the maximal recorded response time reached 0.361 seconds, significantly exceeding the average response time by 72 times. The system demonstrates an average  throughput of 157.395 requests per second. The average standard deviation stood around 0.02 second, highlights a consistent performance, though the disparity between minimum and maximum response times is substantial \ref{tab:rabbitmqdirectsinglemetrics}.  
The latency graph \ref{latencyRabbitMQ1} and  response time graph \ref{responseTimeRabbitMQ1} indicates that there is enormous difference between the time when server send the first chunk of response and fully retriving the message body. For most of the cases the response time is two times longer than latency time.
The difference in reference to other communication patterns is analysed under \ref{latencyvsresponse} paragraph. 

The \ref{latencyRabbitMQ1} presents the latency thought the whole experiment. This graph is very important because it eliminates the time, which took Jmeter to fully retrive the response, however it focuses on the time, which took RabbitMQ to get the message from broker. It can be deduced that the system found a few system overwhelms during the experiment execution. In reference to the \ref{connectTimeRabbitMQ}, this can be deduced that the delay does not rely on the problem with TCP connection establish, which is near to zero. The problem probably is related to the connection to RabbitMQ message broker instance. The first request, which involves the creation of connection to the RabbitMQ, results in the biggest anomaly and equals about 29 seconds. 
%Connect Time

 \begin{figure}[h]
\centering
  \includegraphics[width=1\textwidth]{Experiments/Experiment 1/RABBITMQ/connectovertime.png}
\caption{The connect time diagram for an experiment o on RabbitMQ communication pattern,  with single consumer and 300000 of request.}
\label{connectTimeRabbitMQ}
\end{figure}

% Latency

 \begin{figure}
\centering
  \includegraphics[width=1\textwidth]{Experiments/Experiment 1/RABBITMQ/latencyovertime.png}
\caption{The response latency diagram for an experiment on RabbitMQ communication pattern,  with single consumer and 300000 of request. }
\label{latencyRabbitMQ1}
\end{figure}

% ResonspeTime
 \begin{figure}[h]
\centering
  \includegraphics[width=1\textwidth]{Experiments/Experiment 1/RABBITMQ/responsetimesobertime.png}
\caption{The response time diagram for an experiment on RabbitMQ communication pattern,  with 5 connected clients and 50 thousands of request. }
\label{responseTimeRabbitMQ1}
\end{figure}


%Metrics Table RabbitMQ
\begin{table}[h]
    \centering
    \caption{Performance metrics for consuming 300000 messages, single message per request from RabbitMQ Direct exchange.}
    \label{tab:rabbitmqdirectsinglemetrics}
    \begin{adjustbox}{width=1\textwidth}
        \begin{tabular}{|c|c|c|c|c|c|c|c|}
            \hline
            \textbf{Technology} & \textbf{Average Time (s)} & \textbf{99\% Line Time (s)} & \textbf{MIN Time (s)} & \textbf{Max Time (s)} & \textbf{Throughput (RPS)} & \textbf{Std. Dev.} \\
            \hline
            RabbitMQ & 0.005 & 0.012 & 0.002 & 0.361 & 157.395 & 0.002
\\
            \hline
        \end{tabular}
    \end{adjustbox}
\end{table}

\subparagraph{Azure Service Bus} \mbox{}\\
\label{asb1}

\paragraph{300 000 objects per request, single request }\mbox{}\\
The ~\ref{tab:300000objc} presents the results of getting the list of 300 000 messages within single request. The latency is equal to 23,73, 5349,44s and[], and thoughput is equal to 0.002, 0.42141 and [] for REST, RabbitMQ and Azure Service Bus respecively. 
\begin{table}[h]
    \centering
    \caption{Performance metrics for RabbitMQ Direct All}
    \label{tab:300000objc}
\begin{adjustbox}{width=0.8\textwidth}
\begin{tabular}{|c|c|c|}
    \hline
    \textbf{Pattern} & \textbf{Average Latency (s)}  & \textbf{Throughput (RPS)} \\
    \hline
    RabbitMQ & 5349,44 & 0.002 \\
        Rest & 23,73 & 0.42141 \\
    \hline
\end{tabular}
\end{adjustbox}
\end{table}



\section{Second experiment}
"The client application wants to use the data already processed by the producer application. The data produced by the producer application is placed in various resources, depending on the communication technology (REST, RabbitMQ, Azure Service Bus) that microservices use. The producer application does not need to get information about whether the data has been received by the client. The client receives the data when he needs it, so that he does not store it in his system unnecessarily. The data is consumed by 5 client simultaneously ."

\subsection{Key values of the scenario}
\begin{enumerate}[label=\arabic*.]
      \item \textbf{Asynchronous:} The communication between the producer application and the client application is asynchronous. The client does not wait for the data to be immediately available upon request but retrieves it at a later time.
    
    \item \textbf{Decentralized Data Placement:} The data produced by the producer application is placed in various resources, depending on the communication technology (REST, RabbitMQ, Azure Service Bus) that microservices use. This implies a decentralized approach to data storage and placement.
    
    \item \textbf{Unidirectional Communication:} The data flows from the producer to the consumer (client) in a unidirectional manner for Azure Service bus and RabbitMQ. The producer does not need to know whether the data has been received by the client.
    
    \item \textbf{On-Demand Data Consumption:} The client receives the data when it needs it, ensuring that it does not store unnecessary data locally. This efficient data consumption approach minimizes storage overhead on the client side.
    
    \item \textbf{Parallelism and Scalability:} The data is concurrently consumed by up to 5 clients, enabling multiple clients to access and utilize the processed data. The presence of multiple consumers allows for parallel processing of data. Each consumer can independently retrieve and process data, enabling the system to handle a higher volume of requests simultaneously.
\end{enumerate}
\subsection{Experiment technical arrangement}
\subsubsection{Publisher}
\paragraph{Azure Service Bus Topic publisher}\mbox{}\\
In the context of handling multiple consumers, the Azure Service Bus topics were employed to facilitate the required functionality. The underlying process described under the \ref{sec:firstexperimenttechnicalarrangement} section, responsible for sending messages to an Azure Service Bus queue remains largely analogous, however, in this case the \textbf{ServiceBusClient} object is instantiated with respect to the designated topic name.
The code responsible for publishing messages to Topic in the Azure Service Bus  ~\ref{lst:azurepublishertopicsnippet}.
 \begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of sending messages to the specified topic on the Azure Service Bus.}, label={lst:azurepublishertopicsnippet}]
List<ServiceBusMessage> serviceBusMessages = new List<ServiceBusMessage>();
var serviceBusMessageBatch = await sender.CreateMessageBatchAsync();
for (int i = 0; i < message.Count; i++)
{
    var messageBytes = Encoding.UTF8.GetBytes(String.Join(",", message[i].time, message[i].axis_1, message[i].axis_2, message[i].button_1,        message[i].button_2, message[i].id.ToString()));

    if (!serviceBusMessageBatch.TryAddMessage(new ServiceBusMessage(messageBytes)))
    {
        await sender.SendMessagesAsync(serviceBusMessageBatch);
        serviceBusMessageBatch.Dispose();
        serviceBusMessageBatch = await sender.CreateMessageBatchAsync();
        serviceBusMessageBatch.TryAddMessage(new ServiceBusMessage(messageBytes));
    }
}

await sender.SendMessagesAsync(serviceBusMessageBatch);
\end{lstlisting}
\paragraph{RabbitMQ fanout exchange client publisher}\mbox{}\\
The scenario for publishing messages to the fanout exchange on the RabbitMQ message broker is analogous to publishing messages to direct exchange desciberd under \ref{sec:firstexperimenttechnicalarrangement}. 
Although the functionality has to be extended by declaring each queue for each consumer and their bing to fanout exchange. 

The process is show in code ~\ref{lst:rabbitmqfanoutsnippet}. Messages are published to fanout exchange and then the copy of messages is placed on each queue, which has declared binding to it, by RabbitMQ. 

\begin{lstlisting} [float=h!,caption={Code in C\# presenting the process of sending messages to the fanout exchange on RabbitMQ message broker.}, label={lst:rabbitmqfanoutsnippet}]
channel.ExchangeDeclare(exchange: "my-fanout-exchange", type: ExchangeType.Fanout);

channel.QueueDeclare("consumer1", durable: false, autoDelete: false, exclusive: false);
channel.QueueDeclare("consumer2", durable: false, autoDelete: false, exclusive: false);
channel.QueueDeclare("consumer3", durable: false, autoDelete: false, exclusive: false);
channel.QueueDeclare("consumer4", durable: false, autoDelete: false, exclusive: false);
channel.QueueDeclare("consumer5", durable: false, autoDelete: false, exclusive: false);

channel.QueueBind("consumer1", "my-fanout-exchange", "");
channel.QueueBind("consumer2", "my-fanout-exchange", "");
channel.QueueBind("consumer3", "my-fanout-exchange", "");
channel.QueueBind("consumer4", "my-fanout-exchange", "");
channel.QueueBind("consumer5", "my-fanout-exchange", "");

foreach (Joystick joystick in message)
{
    var id = Guid.NewGuid();
    channel.BasicPublish(exchange: "my-fanout-exchange",
                         routingKey: "",
                         basicProperties: null,
                         body: Encoding.UTF8.GetBytes(String.Join(",", joystick.time, joystick.axis_1, joystick.axis_2, joystick.button_1, joystick.button_2, Guid.NewGuid().ToString())));
}

return Task.CompletedTask;
\end{lstlisting}
    
\paragraph{Representational State Transfer Publisher}\mbox{} \\
In the scenario involving the storage of data generated by a publisher API within the context of the Representational State Transfer communication pattern, catering to multiple consumers, the mechanism described in \nameref{sec:firstexperimenttechnicalarrangement}—originally designed for a singular consumer—remained unaltered, necessitating no supplementary modifications.
\subsubsection{Azure Service Bus Client API}
In both scenarios: 'retrieving individual messages in a single' and 'retrieving all messages in a single request' tthe approach to message consumption bears resemblance to the one described under \nameref{subsec:AzureServiceBusFirst}}. Nevertheless, in subsequent scenario the ServiceBusReceiver object is instantiated using the topic name and subscription, taken from environment variables specified in the docker compose file.
\subsubsection{RabbitMQ Fanout Exchange Client API}
In both scenarios : 'retrieving individual messages in a single' and 'retrieving all messages in a single request' the implementation of he approach to message consumption bears resemblance to the one outlined in \nameref{subsec:rabbitMQFirst}. Nevertheless, in subsequent scenario the name of queue is obtained from environment variables specified in the docker compose file.
\subsubsection{REST Client API}
For both scenarios: 'retrieving individual messages in a single' and 'retrieving all messages in a single request' the implementation of functionality  remains consistent to the functionality discussed in the initial experiment, elaborated in the section \nameref{subsec:restfirst}.

\subsection{Experiments Results}
\subsubsection{Publisher}
\begin{table}[h]
    \centering
    \caption{Performance metrics for publishing 300 000 messages to data stores}
    \label{tab:exp1publishermetrics}
\begin{adjustbox}{width=0.8\textwidth}
\begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Technology}  & \textbf{Response time (s)} & \textbf{Error rate} & \textbf{Throughput (RPS)} \\
    \hline
    Rest  & 6.015 & 0 & 0.166 \\
    \hline
    Azure Service Bus Topic & 1386.359 & 0 & 0.0007 \\
    \hline
    RabbitMq Queue Fanout & 16.291 & 0 & 0.0614 \\
    \hline
\end{tabular}
\end{adjustbox}
\end{table}
\subsubsection{REST}
\begin{table}[h]
    \centering
    \caption{Performance metrics for consuming 50 000 messages, single message per request using REST, with 5 instances of clients requesting data simultaneously }
    \label{tab:exp1publishermetrics}
\begin{adjustbox}{width=1\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \textbf{Label} & \textbf{Average Latency (s)} & \textbf{MIN Latency (s)} & \textbf{MAX Latency (s)} & \textbf{99\% Line Latency (s)} & \textbf{Throughput (RPS)} & \textbf{Std. Dev.} \\
    \hline
    REST CLIENT 1 & 0.266 & 0.046 & 6.352 & 1.304 & 3.273 &  0.254 \\
    REST CLIENT 2 & 0.265 & 0.048 & 10.506 & 1.314 & 3.268 & 0.251 \\
    REST CLIENT 3 & 0.266 & 0.049 & 7.589 & 1.308 & 3.270 & 0.252 \\
    REST CLIENT 4 & 0.265 & 0.048 & 9.060 & 1.312 & 3.275 & 0.251 \\
    REST CLIENT 5 & 0.266 & 0.047 & 10.197 & 1.308 & 3.278 &  0.253 \\
     \hline
    TOTAL & 0.265 & 46 & 10.506 & 1.310 & 16.34 & 0.252 \\
    \hline
\end{tabular}
\end{adjustbox}
\end{table}

The entire experiment took 4h and 15 minutes. The average latency for the experiment took 0.265 s. Each of the client applications achieved a throughput of approximately 3.3 requests per second.The average standard deviation stood around 0.252 seconds, which in relatively high in compared the average latency. This discrepancy   could suggest potential system instability. The the longest time recorded for a request to completed was 10.506s. Additionally, the 99th percentile latency value indicates that there was 1\% of request that took more than 1.2 second to be processed. The difference in processing time, in comparison to the minimal latency value is noteworthy.
 As it is presented on the \ref{latencyrest2} figure, the experiment encountered a period of system overload between 1.15 and 2.20 hours. the system overload between 1h 16m and 2h 20m of experiment. Notably, at the 1h 41m the highest anomaly was observed. This anomaly had a widespread impact, influencing all client applications.

The visual representation in\ref{conenctimerest2} illustrates the time taken by JMeter to establish a connection with REST Client instance. The most significant anomaly occured for Rest Client 1 instance at 1h 16 m where the connect time reached approximately 0.245 s.

Upon analyzing the results in conjunction with those presented the figure \ref{latencyrest2}, it can be deduced that the  exhibiting higher response times are likely experiencing delays on the client side. However the highest response time is closely related to the problems on the publisher application'a side, as the connect time to all client is remains consistently low. The issue consequently affects all  request, regardless of the specific client application that initiated them.

 \begin{figure}
\centering
  \includegraphics[width=1\textwidth]{Experiments/experiment 2/rest/response latencies over time.png}
\caption{The response latencies diagram for an experiment on REST communication pattern,  with 5 connected clients and 50 thousands of request. }
\label{latencyrest2}
\end{figure}

 \begin{figure}
\centering
  \includegraphics[width=1\textwidth]{Experiments/experiment 2/rest/connect times over time.png}
\caption{The connect time diagram for an experiment on REST communication pattern,  with 5 connected clients and 50 000 of request. }
\label{conenctimerest2}
\end{figure}
\subsubsection{RabbitMQ}
\begin{table}[h]
    \centering
    \caption{Performance metrics for consuming 50 000 messages, single message per request from RabbitMQ message broker, with 5 consumers connected simultaneously}
    \label{tab:exp1publishermetrics}
    \begin{adjustbox}{width=1\textwidth}
        \begin{tabular}{|c|c|c|c|c|c|c|}
            \hline
            \textbf{Label} & \textbf{Average Latency (s)} & \textbf{MIN Latency (s)} & \textbf{MAX Latency (s)} & \textbf{99\% Line Latency (s)} & \textbf{Throughput (RPS)} & \textbf{Std. Dev.} \\
            \hline
            Rabbitmq Consumer 1 & 0.008 & 0.003 & 0.282 & 0.029 & 95.977 & 0.006 \\
            Rabbitmq Consumer  2 & 0.008 & 0.003 & 0.280 & 0.029 & 96.593 & 0.006 \\
            Rabbitmq Consumer 3 & 0.008 & 0.003 & 0.282 & 0.029 & 97.375 & 0.006 \\
            Rabbitmq Consumer 4 & 0.008 & 0.003 & 0.223 & 0.030 & 96.144 & 0.006 \\
            Rabbitmq Consumer 5 & 0.008 & 0.003 & 0.230 & 0.030 & 93.916 & 0.006 \\
            \hline
            TOTAL & 0.008 & 0.003 & 0.282 & 0.029 & 469.577 & 0.006 \\
            \hline
        \end{tabular}
    \end{adjustbox}
\end{table}

\subsubsection{Azure Service Bus}

\begin{table}[h]
    \centering
    \caption{Performance metrics for consuming 50 000 messages, single message per request from Azure Service Bus Topic, with 5 consumers connected simultaneously}
    \label{tab:exp2publishermetrics}
    \begin{adjustbox}{width=1\textwidth}
        \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
            \hline
            \textbf{Label}  & \textbf{Average Latency (s)} & \textbf{90\% Line Latency (s)} & \textbf{MIN Latency (s)} & \textbf{MAX Latency (s)} & \textbf{Error \%} & \textbf{Throughput (RPS)} & \textbf{Std. Dev.} \\
            \hline
            Azure Service Bus single Topic1 &  0.331 & 0.385 & 0 & 3.986 & 0.00\% & 2.974 & 0.084 \\
            Azure Service Bus single Topic2 &  0.325 & 0.377 & 0 & 3.737 & 0.00\% & 3.003 & 0.130 \\
            Azure Service Bus single Topic3 &  0.328 & 0.377 & 0 & 3.708 & 0.00\% & 2.996 & 0.112 \\
            Azure Service Bus single Topic4 &  0.325 & 0.395 & 0 & 3.666 & 0.00\% & 3.027& 0.101 \\
            Azure Service Bus single Topic5 &  0.325 & 0.377 & 0 & 2.965 & 0.00\% & 3.016 & 0.068 \\
            \hline
            TOTAL &  0.327 & 0.382 & 0 & 3.986 & 0.00\% & 14.872 & 0.102\\
            \hline
        \end{tabular}
    \end{adjustbox}
\end{table}


\section{Experiments Summary}
\paragraph{Network latency}\mbox{} \\
\label{networklatency}
For all of the performed experiments, results for the Azure Service Bus, a cloud broker representative, are significantly poorer. RabbitMQ message broker has deployed it's instance within the local docker container, as well as Publisher API, from where the data was taken in the REST experiment. All of Client API's are also deployed in the docker containers within the same local environment , and they share the same network with each other. It indicates that the latency between all instances is near to zero. 
Azure Service Bus is located on the server in EAST US Azure region, which has physical location in Richmond in Virginia.   The average network latency to provided data ceneter is about 180 ms. It indicates that within all the request to Azure Service Bus, the latency slows down request finalisation. The connection to Azure Service Bus  also depends on the current server availability. The possibility of getting data from it, requires the token authorization which could also slow down the process.  
To draw more precisely conclusion about the influence of the latency to external messages broker it is necessary to perform more experiment directed to that topic. Exemplary experiment is comparison of connection to the RabbitMQ message broker run on the virtual machine and the one run on the local environment. 

\paragraph{Difference between latency and response time}\mbox{} \\
\label{latencyvsresponse}
 The resulting differences stem from the specific steps involved in processing data in these three cases. RabbitMQ returns message in representation of the bytes, what involves converting the entire response body into a byte array and then further converting that array into a string. This process might introduce more significant delays since it includes two conversions and memory operations. REST Client reads the Publisher's response content directly as a string, bypassing the intermediate step of converting to a byte array. and incurs smaller delays compared to the RabbitMQ approach, as it doesn't involve the added overhead of unnecessary conversions. The \ref{asb1} message body as an array of bytes and decodes  the message body into a UTF-8 encoded string, eliminating the need for an additional conversion steps. This approach is streamlined resulting in minimal delays compared to the RabbitMQ scenario.
%
%This chapter presents the experiments. It is a crucial part of the thesis and has to dominate in the thesis. 
%The experiments and their analysis should be done in the way commonly accepted in the scientific community (eg. benchmark datasets, cross validation of elaborated results, reproducibility and replicability of tests etc).
%
%
%\section{Methodology}
%
%\begin{itemize}
%\item description of methodology of experiments
%\item description of experimental framework (description of user interface of research applications – move to an appendix)
%\end{itemize}
%
%
%\section{Data sets}
%
%\begin{itemize}
%\item description of data sets
%\end{itemize}
%
%
%\section{Results}


%
%
%



\chapter{Summary}
\chapter{Limitations of this study}

Tutaj dopisze co mogłoby być jeszcze przetersowane, co nie udało mi się przetestować 





\begin{appendices}
% TODO
\chapter{Technical documentation}


% TODO
\chapter{List of abbreviations and symbols}

\begin{itemize}
\item[REST] deoxyribonucleic acid
\item[API] model--view--controller 
\item[AMPQ] cardinality of data set
\item[ HTTP] membership function of a fuzzy set
\item[SOA] membership function of a fuzzy set
\item[JAX] deoxyribonucleic acid
\item[ LXC] model--view--controller 
\item[TCP] cardinality of data set
\item[ HTTP] membership function of a fuzzy set
\item[SOA] membership function of a fuzzy set
\item[$\mathbb{E}$] set of edges of a graph
\item[$\mathcal{L}$] Laplace transformation
\end{itemize}



Additional files uploaded to the system include:
\begin{itemize}
\item source code of the application,
\item test data,
\item a video file showing how software or hardware developed for thesis is used,
\item etc.
\end{itemize}

A book on game theory is \cite{basar1995dynamic}.





\listoffigures
\addcontentsline{toc}{chapter}{List of figures}
\listoftables
\addcontentsline{toc}{chapter}{List of tables}

\newpage
\printbibliography           % biblatex
\addcontentsline{toc}{chapter}{Bibliography}
\end{appendices}

\end{document}


%% Finis coronat opus.



%% Finis coronat opus.

